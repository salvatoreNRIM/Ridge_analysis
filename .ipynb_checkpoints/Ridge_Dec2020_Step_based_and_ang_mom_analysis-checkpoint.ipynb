{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from math import acos, degrees\n",
    "from scipy.signal import find_peaks\n",
    "import os.path\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import entropy\n",
    "import pylab as pl\n",
    "from numpy.fft import fft\n",
    "from scipy import stats\n",
    "import numpy\n",
    "from scipy import signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_width = 250\n",
    "#centr_rang = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle3pt(a, b, c):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang = math.degrees(\n",
    "    math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getridofAngleJumps(alpha):\n",
    "    alpha_rad = [x*(np.pi)/180 for x in alpha]\n",
    "    alpha_rad = np.array(alpha_rad)\n",
    "    alpha_rad[~np.isnan(alpha_rad)] = np.unwrap(alpha_rad[~np.isnan(alpha_rad)])\n",
    "    alpha_unwrap= np.degrees(alpha_rad)\n",
    "    return alpha_unwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=20,window='hanning'):\n",
    "#    \"\"\"smooth the data using a window with requested size.\n",
    "#    \n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract RidgeX trajectory from excel file\n",
    "def RidgeX_excel_to_array_preprocessed(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    RidgeX = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    #take just numeric values\n",
    "    RidgeX=pd.to_numeric(RidgeX.iloc[:,0])\n",
    "\n",
    " \n",
    "    return smooth(RidgeX.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail angle trajectory\n",
    "def plot_TailAngle(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000':'tail1_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.1':'tail1_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.2':'tail1_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.3':'tail2_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.4':'tail2_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.5':'tail2_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.6':'tail3_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.7':'tail3_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.8':'tail3_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.9':'tail4_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.10':'tail4_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.11':'tail4_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.12':'tail5_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.13':'tail5_y',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.14':'tail5_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.15':'tail6_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.16':'tail6_y',  \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.17':'tail6_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.18':'tail7_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.19':'tail7_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.20':'tail7_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.21':'tail8_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.22':'tail8_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.23':'tail8_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.tail1_x=pd.to_numeric(df.tail1_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_y=pd.to_numeric(df.tail1_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_lik=pd.to_numeric(df.tail1_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_x=pd.to_numeric(df.tail2_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_y=pd.to_numeric(df.tail2_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_lik=pd.to_numeric(df.tail2_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_x=pd.to_numeric(df.tail3_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_y=pd.to_numeric(df.tail3_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_lik=pd.to_numeric(df.tail3_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail4_x=pd.to_numeric(df.tail4_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail4_y=pd.to_numeric(df.tail4_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail4_lik=pd.to_numeric(df.tail4_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail5_x=pd.to_numeric(df.tail5_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail5_y=pd.to_numeric(df.tail5_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail5_lik=pd.to_numeric(df.tail5_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail6_x=pd.to_numeric(df.tail6_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail6_y=pd.to_numeric(df.tail6_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail6_lik=pd.to_numeric(df.tail6_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail7_x=pd.to_numeric(df.tail7_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail7_y=pd.to_numeric(df.tail7_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail7_lik=pd.to_numeric(df.tail7_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail8_x=pd.to_numeric(df.tail8_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail8_y=pd.to_numeric(df.tail8_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail8_lik=pd.to_numeric(df.tail8_lik[c-chunk_width:c+chunk_width])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.05\n",
    "    df.tail1_x.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail1_y.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_x.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_y.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_x.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_y.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail4_x.where((df.tail4_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail4_y.where((df.tail4_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail5_x.where((df.tail5_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail5_y.where((df.tail5_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail6_x.where((df.tail6_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail6_y.where((df.tail6_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail7_x.where((df.tail7_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail7_y.where((df.tail7_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail8_x.where((df.tail8_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail8_y.where((df.tail8_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles1=[]\n",
    "    angles2=[]\n",
    "    angles3=[]\n",
    "    angles4=[]\n",
    "    angles5=[]\n",
    "    angles6=[]\n",
    "    angles7=[]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        #x1,y1=df.tail1_x[i],df.tail1_y[i]\n",
    "        vertical = np.array([df.tail1_x[i],df.tail1_y[i]+10])\n",
    "        tail1 = np.array([df.tail1_x[i],df.tail1_y[i]])\n",
    "        tail2 = np.array([df.tail2_x[i],df.tail2_y[i]])    \n",
    "        tail3 = np.array([df.tail3_x[i],df.tail3_y[i]])\n",
    "        tail4 = np.array([df.tail4_x[i],df.tail4_y[i]])\n",
    "        tail5 = np.array([df.tail5_x[i],df.tail5_y[i]])    \n",
    "        tail6 = np.array([df.tail6_x[i],df.tail6_y[i]])\n",
    "        tail7 = np.array([df.tail7_x[i],df.tail7_y[i]])\n",
    "        tail8 = np.array([df.tail8_x[i],df.tail8_y[i]])    \n",
    "\n",
    "    #Change below to decide 3 points to determine angle\n",
    "        angle1 = angle3pt(tail2, tail1, vertical)\n",
    "        angle2 = angle3pt(tail3, tail1, vertical)\n",
    "        angle3 = angle3pt(tail4, tail1, vertical)\n",
    "        angle4 = angle3pt(tail5, tail1, vertical)\n",
    "        angle5 = angle3pt(tail6, tail1, vertical)\n",
    "        angle6 = angle3pt(tail7, tail1, vertical)\n",
    "        angle7 = angle3pt(tail8, tail1, vertical)\n",
    "        \n",
    "        #Append\n",
    "        angles1.append(round(angle1,2))\n",
    "        angles2.append(round(angle2,2))\n",
    "        angles3.append(round(angle3,2))\n",
    "        angles4.append(round(angle4,2))\n",
    "        angles5.append(round(angle5,2))\n",
    "        angles6.append(round(angle6,2))\n",
    "        angles7.append(round(angle7,2))\n",
    "\n",
    "    df['Angles1']=angles1\n",
    "    df.head()\n",
    "    df['Angles2']=angles2\n",
    "    df.head()\n",
    "    df['Angles3']=angles3\n",
    "    df.head()\n",
    "    df['Angles4']=angles4\n",
    "    df.head()\n",
    "    df['Angles5']=angles5\n",
    "    df.head()\n",
    "    df['Angles6']=angles6\n",
    "    df.head()\n",
    "    df['Angles7']=angles7\n",
    "    df.head()\n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha1 = df.Angles1\n",
    "    alpha2 = df.Angles2\n",
    "    alpha3 = df.Angles3\n",
    "    alpha4 = df.Angles4\n",
    "    alpha5 = df.Angles5\n",
    "    alpha6 = df.Angles6\n",
    "    alpha7 = df.Angles7\n",
    "\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha1 = smooth(getridofAngleJumps(alpha1))\n",
    "    alpha2 = smooth(getridofAngleJumps(alpha2))\n",
    "    alpha3 = smooth(getridofAngleJumps(alpha3))\n",
    "    alpha4 = smooth(getridofAngleJumps(alpha4))\n",
    "    alpha5 = smooth(getridofAngleJumps(alpha5))\n",
    "    alpha6 = smooth(getridofAngleJumps(alpha6))\n",
    "    alpha7 = smooth(getridofAngleJumps(alpha7))\n",
    "\n",
    "    return alpha1, alpha2, alpha3, alpha4, alpha5, alpha6, alpha7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_RPAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.36':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.37':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.38':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.39':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.40':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.41':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RA_x[i],df.RA_y[i]+10])\n",
    "        RA = np.array([df.RA_x[i],df.RA_y[i]])\n",
    "        RP = np.array([df.RP_x[i],df.RP_y[i]])\n",
    "\n",
    "        angle = angle3pt(RP, RA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_LPAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.27':'LA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.28':'LA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.29':'LA_lik',\n",
    "                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.36':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.37':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.38':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.39':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.40':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.41':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.LA_x=pd.to_numeric(df.LA_x[2:])\n",
    "\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.LA_y=pd.to_numeric(df.LA_y[2:])\n",
    "\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    \n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.LA_lik=pd.to_numeric(df.LA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LA_x.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LA_y.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.LA_x[i],df.LA_y[i]+10])\n",
    "        LA = np.array([df.LA_x[i],df.LA_y[i]])\n",
    "        LP = np.array([df.LP_x[i],df.LP_y[i]])\n",
    "\n",
    "        angle = angle3pt(LP, LA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_HipAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.30':'LH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.31':'LH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.32':'LH_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.33':'RH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.34':'RH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.35':'RH_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.LH_x=pd.to_numeric(df.LH_x[2:])\n",
    "    df.LH_y=pd.to_numeric(df.LH_y[2:])\n",
    "    df.RH_x=pd.to_numeric(df.RH_x[2:])\n",
    "    df.RH_y=pd.to_numeric(df.RH_y[2:])\n",
    "    df.RH_lik=pd.to_numeric(df.RH_lik[2:])\n",
    "    df.LH_lik=pd.to_numeric(df.LH_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.LH_x.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LH_y.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_x.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_y.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    LH_x =  df.LH_x\n",
    "    LH_y =  df.LH_y\n",
    "    RH_x =  df.RH_x    \n",
    "    RH_y =  df.RH_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RH_x[i],df.RH_y[i]+10])\n",
    "        RH = np.array([df.RH_x[i],df.RH_y[i]])\n",
    "        LH = np.array([df.LH_x[i],df.LH_y[i]])\n",
    "\n",
    "        angle = angle3pt(LH, RH, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract centroid X Y trajectory\n",
    "def extract_Centroid(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    CentroidXY = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    CentroidXY.rename(columns={'NaN':'X',\n",
    "                              'NaN.1':'Y'}, \n",
    "                     inplace=True)\n",
    "    #take just numeric values\n",
    "    CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
    "    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "    CentroidX =  np.array(CentroidXY.Centroid_x)\n",
    "    CentroidY =  np.array(CentroidXY.Centroid_y)\n",
    "    return CentroidX, CentroidY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_delay(a, b):\n",
    "    corr_a_b = np.correlate(a-np.mean(a), b-np.mean(b), mode = 'full')\n",
    "    delay = np.where(corr_a_b == numpy.amin(corr_a_b))# -(np.size(corr_a_b)+1)/2\n",
    "    return delay[0]-(np.size(corr_a_b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_Centroid_edge_dist(file_path, chunk_width, i):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "\n",
    "    #Select 1st column csv file\n",
    "    matrix2 = df[df.columns[0]]#.as_matrix()\n",
    "    Centroid1stcol = matrix2.tolist() #file 1st column\n",
    "\n",
    "    #take just numeric values\n",
    "    Centroid1stcol = np.array(pd.to_numeric(Centroid1stcol))\n",
    "\n",
    "    return smooth(Centroid1stcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def firstNonNan(listfloats):\n",
    "    i = 0\n",
    "    for item in listfloats:\n",
    "        i += 1\n",
    "        if math.isnan(item) == False:\n",
    "            return i\n",
    "\n",
    "#firstNonNan(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeaks_extractchunk(x_diff, x, y_r1, y_r2, y_r3, y_r4, y_r5, y_r6, y_r7, \\\n",
    "                           z, w, w_x, t, other_step_x, ba, threshold_height, chunk_width_step):\n",
    "    peaks, _ = find_peaks(x_diff, height=threshold_height, distance = 50, prominence = 1)\n",
    "    out_step = []\n",
    "    out_TA = []\n",
    "    out_HA = []\n",
    "    out_cent = []\n",
    "    out_RstepAng = []\n",
    "    out_cent_X = []\n",
    "    out_ba = []\n",
    "    out_contra_step_x = []\n",
    "    out_ta1_chunk = []\n",
    "    out_ta2_chunk = [] \n",
    "    out_ta3_chunk = [] \n",
    "    out_ta4_chunk = [] \n",
    "    out_ta5_chunk = [] \n",
    "    out_ta6_chunk = [] \n",
    "    out_ta7_chunk = []\n",
    "    for i in np.arange(len(peaks)):\n",
    "        chunk_trial_step = x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_contra_step = other_step_x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA = y_r1[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_HA = z[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_cent = w[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_centX = w_x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_RstepAng = t[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_BA = ba[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA1 = y_r1[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA2 = y_r2[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA3 = y_r3[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA4 = y_r4[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA5 = y_r5[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA6 = y_r6[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA7 = y_r7[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        \n",
    "\n",
    "        out_step.append(chunk_trial_step)\n",
    "        out_TA.append(chunk_trial_TA)\n",
    "        out_HA.append(chunk_trial_HA)\n",
    "        out_cent.append(chunk_trial_cent)\n",
    "        out_cent_X.append(chunk_trial_centX)\n",
    "        out_ba.append(chunk_trial_BA)\n",
    "        out_contra_step_x.append(chunk_trial_contra_step)\n",
    "        out_ta1_chunk.append(chunk_trial_TA1)\n",
    "        out_ta2_chunk.append(chunk_trial_TA2)\n",
    "        out_ta3_chunk.append(chunk_trial_TA3)\n",
    "        out_ta4_chunk.append(chunk_trial_TA4)\n",
    "        out_ta5_chunk.append(chunk_trial_TA5)\n",
    "        out_ta6_chunk.append(chunk_trial_TA6)\n",
    "        out_ta7_chunk.append(chunk_trial_TA7)\n",
    "        #transpose all traces of step angle greater than 360 back to 0\n",
    "        if np.nanmean(chunk_trial_RstepAng) > 250:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng-360)\n",
    "        elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng+360)   \n",
    "        else:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng)\n",
    "\n",
    "\n",
    "    \n",
    "    return out_step, out_TA, out_HA, out_cent, out_cent_X, out_RstepAng, out_contra_step_x, out_ba, out_ta1_chunk, \\\n",
    "            out_ta2_chunk, out_ta3_chunk, out_ta4_chunk, out_ta5_chunk, out_ta6_chunk, out_ta7_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(arr):\n",
    "#     mask = np.isnan(arr)\n",
    "#     idx = np.where(~mask,np.arange(mask.size),0)\n",
    "#     np.maximum.accumulate(idx, out=idx)\n",
    "#     arr[mask] = arr[idx]\n",
    "    df = pd.DataFrame(data=arr.flatten())\n",
    "    df = df.fillna(value=None, method='backfill', axis=None, limit=70, downcast=None)\n",
    "    arr = df.values\n",
    "#    print(type(arr))\n",
    "    return arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
      "<ipython-input-15-39e235f43c31>:52: RuntimeWarning: Mean of empty slice\n",
      "  if np.nanmean(chunk_trial_RstepAng) > 250:\n",
      "<ipython-input-15-39e235f43c31>:54: RuntimeWarning: Mean of empty slice\n",
      "  elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
      "<ipython-input-11-0569cae436c1>:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
      "<ipython-input-11-0569cae436c1>:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n"
     ]
    }
   ],
   "source": [
    "### Organize all data into python dict\n",
    "from collections import defaultdict\n",
    "\n",
    "search_key_path = ['*4mm*', '*_5mm*', '*8mm*', '*10mm*']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "\n",
    "dict_ridge_all = defaultdict(dict)\n",
    "for j in np.arange(len(search_key)):\n",
    "    data_location = \"Z://UusisaariU//PROCESSED_DATA_BACKUPS//nRIM_MEMBERS//Salvo//RD_all_cond//RD_all_cond_analyzed//\"\n",
    "    RidgeX_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Ridge_X//*.csv'))\n",
    "    TA_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'side_cam//*//*.csv'))\n",
    "    Centroid_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Centroid_XY//*.csv'))\n",
    "    BodyAxis_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'BodyAxis//*.csv'))\n",
    "\n",
    "#    print(RidgeX_ExcelList_to_open)\n",
    "#    dict_ridge = {}\n",
    "    for i in np.arange(len(RidgeX_ExcelList_to_open)): # len(peaks)\n",
    "        #Extract arrays\n",
    "        RidgeX_traj = RidgeX_excel_to_array_preprocessed(RidgeX_ExcelList_to_open, chunk_width, i)\n",
    "        CentroidX_traj, CentroidY_traj = extract_Centroid(Centroid_ExcelList_to_open, chunk_width, i)\n",
    "        BodyAxis_traj = RidgeX_excel_to_array_preprocessed(BodyAxis_ExcelList_to_open, chunk_width, i)\n",
    "        #Extract traces of Centroid and Tail Angle around the time frame when the mouse is at the ridge center\n",
    "        a = firstNonNan(CentroidX_traj)\n",
    "        b = round((np.size(CentroidX_traj) - np.count_nonzero(np.isnan(CentroidX_traj)))/2)\n",
    "        c = a + b\n",
    "\n",
    "        #Take tail angle traj after extracting chunk of traj of interest around c\n",
    "        TA1, TA2, TA3, TA4, TA5, TA6, TA7 = plot_TailAngle(TA_ExcelList_to_open, chunk_width, i, c)\n",
    "\n",
    "        RidgeX_traj_chunk = fill_nan(RidgeX_traj[c-chunk_width:c+chunk_width])\n",
    "        TA1_chunk = fill_nan(TA1[c-chunk_width:c+chunk_width])\n",
    "        TA2_chunk = fill_nan(TA2[c-chunk_width:c+chunk_width])\n",
    "        TA3_chunk = fill_nan(TA3[c-chunk_width:c+chunk_width])\n",
    "        TA4_chunk = fill_nan(TA4[c-chunk_width:c+chunk_width])\n",
    "        TA5_chunk = fill_nan(TA5[c-chunk_width:c+chunk_width])\n",
    "        TA6_chunk = fill_nan(TA6[c-chunk_width:c+chunk_width])\n",
    "        TA7_chunk = fill_nan(TA7[c-chunk_width:c+chunk_width])\n",
    "\n",
    "        CentroidX_traj_chunk = (CentroidX_traj[c-chunk_width:c+chunk_width])\n",
    "        CentroidY_traj_chunk = (CentroidY_traj[c-chunk_width:c+chunk_width])\n",
    "        BodyAxis_traj_chunk = fill_nan(BodyAxis_traj[c-chunk_width:c+chunk_width])\n",
    "        HipAngle_traj = plot_HipAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "        HipAngle_traj_chunk = fill_nan(HipAngle_traj[c-chunk_width:c+chunk_width])\n",
    "     \n",
    "        #Compute R and L step \n",
    "        [RPAngle_traj, RP_x, LP_x]   = plot_RPAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "        RP_x = RP_x[c-chunk_width:c+chunk_width]\n",
    "        LP_x = LP_x[c-chunk_width:c+chunk_width]   \n",
    "        RPAngle_traj_chunk = fill_nan(RPAngle_traj[c-chunk_width:c+chunk_width])\n",
    "        \n",
    "        #divide trial into step-based chunks RIGHT\n",
    "        x_r = RP_x-np.nanmean(RP_x)\n",
    "        x_l = LP_x-np.nanmean(LP_x)\n",
    "        x_r_diff = np.diff(RP_x-np.nanmean(RP_x))\n",
    "        x_l_diff = np.diff(-(LP_x-np.nanmean(-LP_x)))\n",
    "        y_r1 = TA1_chunk\n",
    "        y_l1 = TA1_chunk\n",
    "        y_r2 = TA2_chunk\n",
    "        y_l2 = TA2_chunk\n",
    "        y_r3 = TA3_chunk\n",
    "        y_l3 = TA3_chunk\n",
    "        y_r4 = TA4_chunk\n",
    "        y_l4 = TA4_chunk\n",
    "        y_r5 = TA5_chunk\n",
    "        y_l5 = TA5_chunk\n",
    "        y_r6 = TA6_chunk\n",
    "        y_l6 = TA6_chunk\n",
    "        y_r7 = TA7_chunk\n",
    "        y_l7 = TA7_chunk        \n",
    "        w = CentroidY_traj_chunk#-np.nanmean(Centroid_DIST_traj)#*50\n",
    "        z = HipAngle_traj_chunk#-np.nanmean(HipAngle_traj)\n",
    "        t = RPAngle_traj_chunk#-np.nanmean(RPAngle_traj)\n",
    "        ba = BodyAxis_traj_chunk\n",
    "        w_x = CentroidX_traj_chunk\n",
    "        step_chunk_R, TA_chunk_R, HA_chunk_R, cent_chunk_R, cent_chunk_XR, StepAngle_chunk_R, step_chunk_L_wrt_Rstep, \\\n",
    "        ba_wrt_Rstep, ta1_chunk_R, ta2_chunk_R, ta3_chunk_R, \\\n",
    "        ta4_chunk_R, ta5_chunk_R, ta6_chunk_R, ta7_chunk_R  = findpeaks_extractchunk(x_r_diff, x_r, y_r1, y_r2, y_r3, \\\n",
    "                                                                                     y_r4, y_r5, y_r6, y_r7, z, w, w_x, \\\n",
    "                                                                                     t, x_l, ba, 0.9, chunk_width//2)\n",
    "        \n",
    "        #divide trial into step-based chunks LEFT\n",
    "        step_chunk_L, TA_chunk_L, HA_chunk_L, cent_chunk_L, cent_chunk_XL, StepAngle_chunk_L, step_chunk_R_wrt_Lstep, \\\n",
    "        ba_wrt_Lstep, ta1_chunk_L, ta2_chunk_L, ta3_chunk_L, \\\n",
    "        ta4_chunk_L, ta5_chunk_L, ta6_chunk_L, ta7_chunk_L  = findpeaks_extractchunk(x_l_diff, x_l, y_l1, y_l2, y_l3, \\\n",
    "                                                                                     y_l4, y_l5, y_l6, y_l7, \\\n",
    "                                                                                     z, w, w_x, t, x_r, ba, 0.9, chunk_width//2)\n",
    "        \n",
    "        \n",
    "        #Decide here what variables to plot in the three figures\n",
    "        var1 = np.array(RidgeX_traj_chunk)\n",
    "        var2 = np.array(TA1_chunk)\n",
    "        var3 = np.array(CentroidX_traj_chunk)\n",
    "        var4 = step_chunk_R\n",
    "        var5 = TA_chunk_R\n",
    "        var6 = step_chunk_L\n",
    "        var7 = TA_chunk_L\n",
    "        var8 = StepAngle_chunk_R\n",
    "        var9 = StepAngle_chunk_L\n",
    "        var10 = cent_chunk_R\n",
    "        var11 = cent_chunk_L\n",
    "        var12 = cent_chunk_XR\n",
    "        #var13 = cent_DistChunk_R\n",
    "        var13 = HA_chunk_R\n",
    "        var14 = StepAngle_chunk_R\n",
    "        var15 = step_chunk_L_wrt_Rstep\n",
    "        var16 = ba_wrt_Rstep\n",
    "        var17 = ba_wrt_Lstep\n",
    "        var18 = HA_chunk_L\n",
    "        var19 = [ta1_chunk_R, ta2_chunk_R, ta3_chunk_R, ta4_chunk_R, ta5_chunk_R, ta6_chunk_R, ta7_chunk_R]\n",
    "        var20 = [ta1_chunk_L, ta2_chunk_L, ta3_chunk_L, ta4_chunk_L, ta5_chunk_L, ta6_chunk_L, ta7_chunk_L]\n",
    "            \n",
    "        #Make dict\n",
    "        key_file_name = os.path.basename(RidgeX_ExcelList_to_open[i])\n",
    "        #print(key_file_name)\n",
    "        dict_ridge_all[search_key[j]][key_file_name] = [var1, var2, var3, var4, var5, var6, var7, \\\n",
    "                                                        var8, var9, var10, var11, var12, var13, var14, var15, \\\n",
    "                                                        var16, var17, var18, var19, var20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_dict_value_ridge_pos(dict_ridge):\n",
    "    #Divide trials based on ridge position. Assign -1 for left tilt, +1 for right and 0 for no tilts. Append to 4th col\n",
    "    #Changed the threshold from 5000 to 10000 bcs M53 detected many no pert trials as pert\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "\n",
    "        ridge_array = dict_ridge[key_list[i]][0]\n",
    "        ridge_array_translated_nonNaN = ridge_array[~np.isnan(ridge_array)]\n",
    "        ridge_array_translated_nonNaN_mean_centered = ridge_array_translated_nonNaN-  \\\n",
    "        np.nanmean(smooth(ridge_array_translated_nonNaN[20:40]))\n",
    "        ridge_array_translated_int = np.trapz(smooth(ridge_array_translated_nonNaN_mean_centered, 50))\n",
    "        ridge_array_translated_nonNaN_mean_centered_diff_max = max(np.diff(ridge_array_translated_nonNaN_mean_centered))\n",
    "        if ridge_array_translated_int < -3000 and ridge_array_translated_nonNaN_mean_centered_diff_max<40:\n",
    "            dict_ridge[key_list[i]].append(-1)\n",
    "            #print(ridge_array_translated_nonNaN_mean_centered_diff_max)\n",
    "        elif ridge_array_translated_int > +3000 and ridge_array_translated_nonNaN_mean_centered_diff_max<40:\n",
    "            dict_ridge[key_list[i]].append(1)\n",
    "    #        print(ridge_array_translated_int)\n",
    "\n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append(0)    \n",
    "    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_pert_trials_from_dict(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    for i in np.arange(len(key_list)):\n",
    "        Ridge_classvalue = values_list[i][-1]\n",
    "        if Ridge_classvalue == 1 or Ridge_classvalue == -1:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeNaNTATraces(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is mostly NaN\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][1]\n",
    "        no_of_nan_TAtraj = list(np.isnan(TA_traj))\n",
    "        count_NaN = no_of_nan_TAtraj.count(1)\n",
    "        if count_NaN>70:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)\n",
    "        elif len(TA_traj) == 0:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_traces_0_360_range(dict_ridge):\n",
    "    #Transpose from dict all trials where the TA traj is outsude [0, 360] and append to 13th column \n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    #dict_TA_transpose = {}\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        key_to_change = key_list[i]\n",
    "        TA_to_append = []\n",
    "        for j in np.arange(len(TA_traj)):\n",
    "            if np.nanmean(TA_traj[j])>400:\n",
    "                TA_traj_pushed_down = TA_traj[j]-360\n",
    "                TA_to_append.append(TA_traj_pushed_down)      \n",
    "            elif np.nanmean(TA_traj[j])<-100:\n",
    "                TA_traj_pushed_up = TA_traj[j]+360\n",
    "                TA_to_append.append(TA_traj_pushed_up)\n",
    "            else:\n",
    "                TA_to_append.append(TA_traj[j])\n",
    "        dict_ridge[key_to_change].append(TA_to_append)    \n",
    "\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesNON_0_360(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is outside 0 to 360 \n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        for j in np.arange(len(TA_traj)):\n",
    "            #print(len(TA_traj))\n",
    "            if np.nanmean(TA_traj[j])>350:\n",
    "                TA_traj[j] = []\n",
    "            elif np.nanmean(TA_traj[j]) < 10:\n",
    "                TA_traj[j] = []\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesHighDerivative(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        for j in np.arange(len(TA_traj)): # step\n",
    "            TA_diff = np.diff(TA_traj[j])\n",
    "            if np.any(TA_diff>8) or np.any(TA_diff<-8):\n",
    "                TA_traj[j] = []\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_TA_ipsi_contra_within0_360_range(TA_traj):\n",
    "    if np.nanmean(TA_traj)>400:\n",
    "        TA_traj = TA_traj-360\n",
    "    elif np.nanmean(TA_traj)<-40:\n",
    "        TA_traj = TA_traj+360\n",
    "    return TA_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR, TA_traj_listwrtL):\n",
    "    #I am transforming TA such that CCW rotation will increase the angle value\n",
    "    TA_wrtIpsiStep = []\n",
    "    TA_wrtContraStep = []\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) < 180:\n",
    "        TA_wrtIpsiStep = TA_traj_listwrtR\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) > 180:\n",
    "        TA_wrtIpsiStep = -TA_traj_listwrtL+360\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) > 180:\n",
    "        TA_wrtContraStep = -TA_traj_listwrtR+360\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) < 180:\n",
    "        TA_wrtContraStep = TA_traj_listwrtL\n",
    "    return TA_wrtIpsiStep, TA_wrtContraStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_HA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR, TA_traj_listwrtL, Hip_traj_list_wrt_R, Hip_traj_list_wrt_L):\n",
    "    #I am transforming HA such that CCW rotation will increase the angle value\n",
    "    Hip_wrtIpsiStep = []\n",
    "    Hip_wrtContraStep = []\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) < 180:\n",
    "        Hip_wrtIpsiStep = Hip_traj_list_wrt_R\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) > 180:\n",
    "        Hip_wrtIpsiStep = -Hip_traj_list_wrt_L+360+180\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) > 180:\n",
    "        Hip_wrtContraStep = -Hip_traj_list_wrt_R+360+180\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) < 180:\n",
    "        Hip_wrtContraStep = Hip_traj_list_wrt_L\n",
    "    return Hip_wrtIpsiStep, Hip_wrtContraStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ta_segments(tailseg_listR, tailseg_listL, j, k):\n",
    "    #take as input the list of tail segments and process them into ipsiVscontra before putting them in dict\n",
    "    TA_ipsi_seg_list = []\n",
    "    TA_contra_seg_list = []\n",
    "#     print(len(tailseg_listR[0]), len(tailseg_listL[0]))\n",
    "#     for j, k in zip(np.arange(len(tailseg_listR)), np.arange(len(tailseg_listL))):\n",
    "    for t in np.arange(7):\n",
    "        TA_traj_listwrtR_T = transpose_TA_ipsi_contra_within0_360_range(tailseg_listR[t][j])\n",
    "        TA_traj_listwrtL_T = transpose_TA_ipsi_contra_within0_360_range(tailseg_listL[t][k])\n",
    "\n",
    "        #divide TA traces based on contra step\n",
    "        TA_wrtIpsiStep, TA_wrtContraStep = decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                               TA_traj_listwrtL_T)\n",
    "        TA_ipsi_seg_list.append(TA_wrtIpsiStep)\n",
    "        TA_contra_seg_list.append(TA_wrtContraStep)\n",
    "        \n",
    "    return TA_ipsi_seg_list, TA_contra_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeemptyarray(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high and return to COL 15\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_listwrtR = values_list[i][4]\n",
    "        tailseg_list_R = values_list[i][18]\n",
    "        tailseg_list_L = values_list[i][19]\n",
    "        #print(len(tailseg_list_R), len(tailseg_list_L))\n",
    "\n",
    "        TA_traj_listwrtL = values_list[i][6]\n",
    "        COM_traj_list = values_list[i][9]\n",
    "        COMX_traj_list = values_list[i][11]\n",
    "        Hip_traj_list_wrt_R = values_list[i][12]\n",
    "        Hip_traj_list_wrt_L = values_list[i][17]\n",
    "        StepAnlge_traj_list = values_list[i][13]\n",
    "        ContraStep_traj_list = values_list[i][14]\n",
    "        Step_x_traj_list = values_list[i][3]\n",
    "        values_to_append = []\n",
    "        for j, k in zip(np.arange(len(TA_traj_listwrtR)), np.arange(len(TA_traj_listwrtL))):\n",
    "            if len(TA_traj_listwrtR[j]) and len(COM_traj_list[j]):\n",
    "                #Transpose traces beyond 0-360 and exclude traces that are still beyon range\n",
    "                TA_traj_listwrtL_T = transpose_TA_ipsi_contra_within0_360_range(TA_traj_listwrtL[k])\n",
    "                TA_traj_listwrtR_T = transpose_TA_ipsi_contra_within0_360_range(TA_traj_listwrtR[j])\n",
    "                #divide TA traces based on contra step\n",
    "                TA_wrtIpsiStep, TA_wrtContraStep = decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                                       TA_traj_listwrtL_T)\n",
    "                HA_wrtIpsiStep, HA_wrtContraStep = decide_HA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                                       TA_traj_listwrtL_T, \\\n",
    "                                                                                       Hip_traj_list_wrt_R[j], \\\n",
    "                                                                                       Hip_traj_list_wrt_L[k])\n",
    "                #process tail segments\n",
    "                processed_ta_seg_ipsi_list, processed_ta_seg_contra_list = process_ta_segments(tailseg_list_R, \\\n",
    "                                                                                               tailseg_list_L, j, k)\n",
    "                #Assign to value in dict\n",
    "                values_to_append.append([TA_traj_listwrtR[j], COM_traj_list[j], COMX_traj_list[j], \\\n",
    "                                         #COMdist_traj_list[j], Hip_traj_list[j], StepAnlge_traj_list[j],\\\n",
    "                                         Hip_traj_list_wrt_R[j], StepAnlge_traj_list[j],\\\n",
    "                                         Step_x_traj_list[j], StepAnlge_traj_list[j], TA_wrtContraStep, \\\n",
    "                                         TA_wrtIpsiStep, TA_traj_listwrtL[k], ContraStep_traj_list[j], \\\n",
    "                                         Hip_traj_list_wrt_L[k], HA_wrtIpsiStep, HA_wrtContraStep, \\\n",
    "                                         processed_ta_seg_contra_list, processed_ta_seg_ipsi_list])\n",
    "\n",
    "        dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstNonNan(listfloats):\n",
    "    i = 0\n",
    "    for item in listfloats:\n",
    "        i += 1\n",
    "        if math.isnan(item) == False:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write script to pre-process and organize all pert trial into python dict\n",
    "\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "\n",
    "dict_preprocessed_all = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    dict_ridge = dict_ridge_all[search_key[i]]\n",
    "    dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "    dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "    dict_ridge_excl_nan_traces = excludeNaNTATraces(dict_ridge_el_pert_trial)\n",
    "    dict_TA_transpose = transpose_traces_0_360_range(dict_ridge_excl_nan_traces)\n",
    "    dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = excludeemptyarray(dict_TA_transpose)#dict_TA_transpose_btw_0_360)\n",
    "    dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PLOTS BEFORE PRE-PROCESS wrt R STEP\n",
    "#Plot trials for a specific width where all trials from the same animal are plot in the same plot (tot 15 plots) \n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "    dict_ridge_Xwidth = dict_ridge_all['4mm']\n",
    "    dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "    key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "#    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)    \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][4]\n",
    "        #print(TA_traj_wrt_step)\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            plt.plot(TA_traj_wrt_step[j] ,'y')\n",
    "            plt.title(\"{i}\".format(i = key_list[i]))\n",
    "            #plt.ylim(200, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################PLOTS BEFORE PRE-PROCESS wrt L STEP\n",
    "#Plot trials for a specific width where all trials from the same animal are plot in the same plot (tot 15 plots) \n",
    "MouseID_key = [ 'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "list_TA_traj = []\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "    dict_ridge_Xwidth = dict_ridge_all['4mm']\n",
    "    dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "    key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "#    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    fig = plt.figure()\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][6]\n",
    "        clrs = sns.color_palette(\"viridis\", n_colors=8) \n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            if all(TA_traj_wrt_step[j]<220) and all(TA_traj_wrt_step[j]>-50) and len(TA_traj_wrt_step[j])==250:\n",
    "                x = np.linspace(0, 250/300, 250)\n",
    "                ax1.plot(x, TA_traj_wrt_step[j] ,color=clrs[0], lw=1, alpha = 0.4)\n",
    "                #plt.title(\"{i}\".format(i = key_list[i]))\n",
    "                #plt.ylim(200, 300)\n",
    "                list_TA_traj.append(TA_traj_wrt_step[j])\n",
    "    ax1.plot(x, np.nanmean(list_TA_traj, axis = 0), color=clrs[0], lw=3, alpha = 1)    \n",
    "    ax1.set_xlabel('Time (s)', fontsize=24)\n",
    "    ax1.set_ylabel('Tail angle (degree)', fontsize=24)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=18) \n",
    "    fig.savefig('out.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################PLOTS BEFORE PRE-PROCESS wrt L STEP\n",
    "#Plot hips and tail to visually check they are anti-phase. Look at example M61\n",
    "MouseID_key = [ 'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "list_TA_traj = []\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "    dict_ridge_Xwidth = dict_ridge_all['4mm']\n",
    "    dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "    key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "#    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    fig = plt.figure()\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][6]\n",
    "        HA_traj_wrt_step = values_list[i][12]\n",
    "        clrs = sns.color_palette(\"viridis\", n_colors=8) \n",
    "        for j, k in zip(np.arange(len(TA_traj_wrt_step)), np.arange(len(HA_traj_wrt_step))):\n",
    "            if len(TA_traj_wrt_step[j])==250:# and len(HA_traj_wrt_step[j]) == len(TA_traj_wrt_step[j]):\n",
    "                x = np.linspace(0, 250/300, 250)\n",
    "                ax1.plot((TA_traj_wrt_step[j]-np.nanmean(TA_traj_wrt_step[j]))/2 ,color=clrs[4], lw=1, alpha = 0.4)\n",
    "                ax1.plot(HA_traj_wrt_step[k]-np.nanmean(HA_traj_wrt_step[k]) ,color=clrs[0], lw=1, alpha = 0.4)\n",
    "                #plt.title(\"{i}\".format(i = key_list[i]))\n",
    "                #plt.ylim(200, 300)\n",
    "                list_TA_traj.append(TA_traj_wrt_step[j])\n",
    "    #ax1.plot(x, np.nanmean(list_TA_traj, axis = 0), color=clrs[0], lw=3, alpha = 1)    \n",
    "    ax1.set_xlabel('Time (s)', fontsize=24)\n",
    "    ax1.set_ylabel('Tail angle (degree)', fontsize=24)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=18) \n",
    "    fig.savefig('out.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTA_outrange(TA):\n",
    "    if any(i < -30 or i > 250 for i in TA):\n",
    "        TA = []\n",
    "    return TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#####Compute PSTH no pert trial with mean trace for each mouse and each width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################################################################PLOTS BEFORE PRE-PROCESS wrt L STEP\n",
    "#Plot trials for a specific width where all trials from the same animal are plot in the same plot (tot 15 plots) \n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "MouseID_key = [ 'M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "clrs = sns.color_palette(\"husl\", 4)\n",
    "label_strings = ['4mm Tail', '5mm Tail', '8mm Tail', '10mm Tail']\n",
    "\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "for k in np.arange(len(search_key)):\n",
    "    TA_mean_1_Mouse = []\n",
    "    for i in np.arange(len(MouseID_key)):\n",
    "        list_TA_traj = []\n",
    "        dict_ridge_Xwidth = dict_ridge_all[search_key[k]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "\n",
    "        for i in np.arange(len(key_list)):\n",
    "            TA_traj_wrt_step = values_list[i][6]\n",
    "            #clrs = sns.color_palette(\"viridis\", n_colors=8) \n",
    "            for j in np.arange(len(TA_traj_wrt_step)):\n",
    "                if len(TA_traj_wrt_step[j])==250:#all(TA_traj_wrt_step[j]<220) and all(TA_traj_wrt_step[j]>-50) and len(TA_traj_wrt_step[j])==250:\n",
    "                    list_TA_traj.append(TA_traj_wrt_step[j])\n",
    "        ax1.plot(x, np.nanmean(list_TA_traj, axis = 0), c=clrs[k], lw=0.8, alpha = 0.3)\n",
    "        TA_mean_1_Mouse.append(np.nanmean(list_TA_traj, axis = 0))\n",
    "    #Plot mean across mice for 1 width\n",
    "    ax1.axvline(125/300,0,360, color = 'red')\n",
    "    ax1.plot(x, np.nanmean(TA_mean_1_Mouse, axis = 0), c=clrs[k], label = label_strings[k], lw=3, alpha = 0.8)\n",
    "    ax1.legend(loc=\"lower left\", prop={'size': 12})\n",
    "    ax1.set_xlabel('Time (s)', fontsize=24)\n",
    "    ax1.set_ylabel('Tail angle (degree)', fontsize=24)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=18) \n",
    "    fig.savefig('nopertTA_allMiceallWidth.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_amlpit(vector):\n",
    "    ampl = max(vector[92:132])-min(vector[92:132])\n",
    "    return ampl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Mean_STD_forPSTH(array_value_dict):\n",
    "    mean_array = np.nanmean(array_value_dict, axis = 0)\n",
    "    STD_array = stats.sem(array_value_dict, nan_policy='omit')\n",
    "    return mean_array, STD_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### PLOT POST PROCESS\n",
    "#Plot hips and tail angles for all trials, and compute amplitude of those arrays\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "#fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "mean_big_list = []\n",
    "std_big_list = []\n",
    "mean_small_list = []\n",
    "std_small_list = []\n",
    "mean_combo_list = []\n",
    "dict_TA_HA_ampl = defaultdict(dict)\n",
    "\n",
    "\n",
    "for k in np.arange(len(search_key)):  \n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    TA_ampl_list = []\n",
    "    HA_ampl_list = []\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all[search_key[k]]\n",
    "    values_list = list(dict_ridge_Xwidth.values())\n",
    "    key_list = list(dict_ridge_Xwidth.keys()) \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][-1]\n",
    "        COMX_traj_wrt_step = values_list[i][-1] \n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            ax1.axvline(92,0,360, color = 'red')\n",
    "            ax1.axvline(132,0,360, color = 'red')\n",
    "\n",
    "            Tail_idx = 7\n",
    "            Hip_idx = 13\n",
    "            Tail_idx1 = 0\n",
    "            Tail_idx2 = 3\n",
    "            if len(COMX_traj_wrt_step[j][Tail_idx]):# Plot Tail Angle trajectory\n",
    "                plt.plot(COMX_traj_wrt_step[j][Tail_idx] ,color = 'b', lw=0.5, alpha = 0.1)\n",
    "                if len(COMX_traj_wrt_step[j][Tail_idx]) == 250:\n",
    "                    TA_ampl = compute_amlpit(COMX_traj_wrt_step[j][Tail_idx])\n",
    "                    TA_ampl_list.append(TA_ampl)#Ampl TA\n",
    "            if len(COMX_traj_wrt_step[j][Hip_idx]): #Plot Hip Angle trajectory\n",
    "                wrapped_angle =  np.unwrap((COMX_traj_wrt_step[j][Hip_idx]+1800)%(360))\n",
    "                plt.plot(wrapped_angle, color = 'r', lw=0.5, alpha = 0.1)\n",
    "                if len(COMX_traj_wrt_step[j][Hip_idx]) == 250:\n",
    "                    HA_ampl = compute_amlpit(wrapped_angle)\n",
    "                    HA_ampl_list.append(HA_ampl)#Ampl Hips\n",
    "    dict_TA_HA_ampl[search_key[k]] = HA_ampl_list#, HA_ampl_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, ls_param, label_strings):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    #label_strings = ['4mm', '5mm', '8mm', '10mm']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            x = np.linspace(0, 250/300, 250)\n",
    "            ax.plot(x, mean_array[i], c=clrs[i], label = label_strings[i], ls = ls_param)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.3, facecolor=clrs[i])\n",
    "            ax.legend(loc=\"lower left\", prop={'size': 12})\n",
    "            #ax.set_xlabel('Time (s)', fontsize=18)\n",
    "            ax.set_ylabel('Angle (degree)', fontsize=18)\n",
    "            #ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "            ax.axvline(125/300,0,360, color = 'red')\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTRA\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "label_strings_bl = ['4mm Hip', '5mm Hip', '8mm Hip', '10mm Hip']\n",
    "label_strings_sl = ['4mm Tail', '5mm Tail', '8mm Tail', '10mm Tail']\n",
    "ls_param_bl = '--'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl)  \n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "plt.xlim(50/300, 200/300)\n",
    " \n",
    "plt.savefig('no_pert_AngMomPSTH.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot mean across all trials of TA and HA trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "mean_big_list = []\n",
    "std_big_list = []\n",
    "mean_small_list = []\n",
    "std_small_list = []\n",
    "mean_combo_list = []\n",
    "TA_up_thresh = []\n",
    "TA_below_thresh = []\n",
    "a = 0\n",
    "for k in np.arange(len(search_key)):    \n",
    "\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all[search_key[k]]\n",
    "    values_list = list(dict_ridge_Xwidth.values())\n",
    "    key_list = list(dict_ridge_Xwidth.keys()) \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][-1]\n",
    "        COMX_traj_wrt_step = values_list[i][-1] \n",
    "        #print(TA_traj_wrt_step)\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            Tail_idx = 7\n",
    "            Hip_idx = 13\n",
    "            Tail_idx1 = 0\n",
    "            Tail_idx2 = 3\n",
    "            if len(COMX_traj_wrt_step[j][Tail_idx]):# Plot Tail Angle trajectory\n",
    "                a = a+1\n",
    "                #print(a)\n",
    "                plt.plot(COMX_traj_wrt_step[j][Tail_idx] ,color = 'b', lw=0.5, alpha = 0.1)\n",
    "                #plt.ylim(-50,420)\n",
    "                if len(COMX_traj_wrt_step[j][Tail_idx]) == 250:\n",
    "                    TA_below_thresh.append(COMX_traj_wrt_step[j][Tail_idx]-COMX_traj_wrt_step[j][Tail_idx][100])#(np.diff(COMX_traj_wrt_step[j][Tail_idx]))*0.5*(1/3)*49)#Ang Mom TA\n",
    "            if len(COMX_traj_wrt_step[j][Hip_idx]): #Plot Hip Angle trajectory\n",
    "                plt.plot(COMX_traj_wrt_step[j][Hip_idx] ,color = 'r', lw=0.5, alpha = 0.1)\n",
    "                if len(COMX_traj_wrt_step[j][Hip_idx]) == 250:\n",
    "                    TA_up_thresh.append(COMX_traj_wrt_step[j][Hip_idx]-COMX_traj_wrt_step[j][Hip_idx][100])#(np.diff(COMX_traj_wrt_step[j][Hip_idx]))*10*0.5*4)#Ang Mom HA\n",
    "mean_big, std_big = return_Mean_STD_forPSTH(TA_up_thresh)\n",
    "mean_small, std_small = return_Mean_STD_forPSTH(TA_below_thresh)\n",
    "mean_big_list.append(mean_big)\n",
    "std_big_list.append(std_big)\n",
    "mean_small_list.append(mean_small)\n",
    "std_small_list.append(std_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, ls_param, label_strings):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    #label_strings = ['4mm', '5mm', '8mm', '10mm']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            x = np.linspace(0, 250/300, 250)\n",
    "            ax.plot(x, mean_array[i], c='gray', label = label_strings[i], ls = ls_param)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.3, facecolor='gray')\n",
    "            ax.legend(loc=\"lower left\", prop={'size': 12})\n",
    "            #ax.set_xlabel('Time (s)', fontsize=18)\n",
    "            ax.set_ylabel('Angle (degree)', fontsize=18)\n",
    "            #ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "            ax.axvline(125/300,0,360, color = 'red')\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTRA\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette('pastel', 9)\n",
    "label_strings_bl = ['Hip']\n",
    "label_strings_sl = ['Tail']\n",
    "ls_param_bl = '--'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl)  \n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "plt.xlim(50/300, 200/300)\n",
    " \n",
    "plt.savefig('no_pert_AngMomPSTH.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot mean across all trials of TA and HA angular momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "mean_big_list = []\n",
    "std_big_list = []\n",
    "mean_small_list = []\n",
    "std_small_list = []\n",
    "mean_combo_list = []\n",
    "TA_up_thresh = []\n",
    "TA_below_thresh = []\n",
    "cum_ta_ang_mom_list = []\n",
    "cum_ha_ang_mom_list = []\n",
    "AngMom_TA_and_HA = []\n",
    "mean_combined_list = []\n",
    "std_combined_list = []\n",
    "a = 0\n",
    "cum_ang_mom_dict = defaultdict(dict)\n",
    "\n",
    "for k in np.arange(len(search_key)):    \n",
    "\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all[search_key[k]]\n",
    "    values_list = list(dict_ridge_Xwidth.values())\n",
    "    key_list = list(dict_ridge_Xwidth.keys()) \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][-1]\n",
    "        COMX_traj_wrt_step = values_list[i][-1] \n",
    "        #print(TA_traj_wrt_step)\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            Tail_idx = 7\n",
    "            Hip_idx = 13\n",
    "            Tail_idx1 = 0\n",
    "            Tail_idx2 = 3\n",
    "            if len(COMX_traj_wrt_step[j][Tail_idx]) and len(COMX_traj_wrt_step[j][Hip_idx]):# Plot Tail Angle trajectory\n",
    "                ang_mom_ta = (smooth((np.diff(COMX_traj_wrt_step[j][Tail_idx]))*0.5*(1/3)*49, 10))\n",
    "                ang_mom_ha = (smooth((np.diff(COMX_traj_wrt_step[j][Hip_idx]))*10*0.5*4, 10))\n",
    "\n",
    "                #plt.ylim(-50,420)\n",
    "                if len(COMX_traj_wrt_step[j][Tail_idx]) == 250 and len(COMX_traj_wrt_step[j][Hip_idx]) == 250:\n",
    "                    TA_up_thresh.append(ang_mom_ha)#Ang Mom HA\n",
    "                    cum_ha_ang_mom = np.trapz(abs(ang_mom_ha[90:150]))\n",
    "                    cum_ha_ang_mom_list.append(cum_ha_ang_mom)\n",
    "                    TA_below_thresh.append(ang_mom_ta)#Ang Mom TA\n",
    "                    AngMom_TA_and_HA.append(ang_mom_ta+ang_mom_ha)#Ang Mom TA + HA                   \n",
    "                    cum_ta_ang_mom = np.trapz(abs(ang_mom_ta[90:150])) #event btw 0.3-0.5 s\n",
    "                    cum_ta_ang_mom_list.append(cum_ta_ang_mom)\n",
    "                    #plot\n",
    "                    plt.plot(ang_mom_ta ,color = 'b', lw=0.05, alpha = 0.1)\n",
    "                    plt.plot(ang_mom_ha ,color = 'r', lw=0.05, alpha = 0.1)\n",
    "                    plt.plot(ang_mom_ha+ang_mom_ta, color = 'k', lw=0.05, alpha = 0.1)\n",
    "\n",
    "            plt.ylim(-100,250)\n",
    "cum_ang_mom_dict['all'] = cum_ha_ang_mom_list#, cum_ta_ang_mom_list\n",
    "print(len(cum_ta_ang_mom_list), len(cum_ha_ang_mom_list))\n",
    "mean_big, std_big = return_Mean_STD_forPSTH(TA_up_thresh)\n",
    "mean_small, std_small = return_Mean_STD_forPSTH(TA_below_thresh)\n",
    "mean_combined, std_combined = return_Mean_STD_forPSTH(AngMom_TA_and_HA)\n",
    "mean_big_list.append(mean_big)\n",
    "std_big_list.append(std_big)\n",
    "mean_small_list.append(mean_small)\n",
    "std_small_list.append(std_small)\n",
    "mean_combined_list.append(mean_combined)\n",
    "std_combined_list.append(std_combined)\n",
    "\n",
    "# cum_ta_ang_mom_list.append(cum_ta_ang_mom)\n",
    "# cum_ha_ang_mom_list.append(cum_ha_ang_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, ls_param, label_strings, clr):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    #label_strings = ['4mm', '5mm', '8mm', '10mm']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            x = np.linspace(0, 250/300, 258)\n",
    "            ax.plot(x, mean_array[i], c=clr, label = label_strings[i], ls = ls_param)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.3, facecolor=clr)\n",
    "            ax.legend(loc=\"lower left\", prop={'size': 12})\n",
    "            #ax.set_xlabel('Time (s)', fontsize=18)\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "            ax.axvline(92/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(152/300,0,360, color = 'gray', lw=0.2)\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTRA\n",
    "_, ax = plt.subplots(figsize=(14, 8))\n",
    "clrs = ['lightcoral', 'grey']\n",
    "label_strings_bl = ['Hip']\n",
    "label_strings_sl = ['Tail']\n",
    "ls_param_bl = '-'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl, clrs[1]) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl, clrs[0])  \n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "plt.xlim(50/300, 200/300)\n",
    " \n",
    "plt.savefig('no_pert_AngMomPSTH.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COMPUTE AND PLOT COMBINED TRACE FROM ABOVE SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, ls_param, label_strings, clr):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    #label_strings = ['4mm', '5mm', '8mm', '10mm']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            x = np.linspace(0, 250, 258)\n",
    "            ax.plot(x, mean_array[i], c=clr, label = label_strings[i], ls = ls_param)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.3, facecolor=clr)\n",
    "            ax.legend(loc=\"lower left\", prop={'size': 12})\n",
    "            ax.set_xlabel('Time (s)', fontsize=18)\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "            ax.axvline(125,0,360, color = 'red')\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot combined trace as well\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = ['lightcoral', 'grey', 'red']\n",
    "label_strings_bl = ['Hip']\n",
    "label_strings_sl = ['Tail']\n",
    "label_strings_co = ['Tail+Hip']\n",
    "\n",
    "ls_param_bl = '-'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl, clrs[1]) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl, clrs[0])\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combined_list, std_combined_list, ax, ls_param_sl, label_strings_co, clrs[2]) \n",
    "\n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "#plt.xlim(50/300, 200/300)\n",
    " \n",
    "plt.savefig('no_pert_AngMomPSTH.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save values into dict\n",
    "\n",
    "data = cum_ang_mom_dict\n",
    "import pandas as pd\n",
    "\n",
    "(pd.DataFrame.from_dict(data=data, orient='index')\n",
    "   .to_csv('cum_ang_mom_dict.csv', header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitsequenceequally(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        array_to_append = seq[int(last):int(last + avg)]\n",
    "        out.append(np.trapz(array_to_append))\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot difference in ang mom between tail and hips wrt step cycle\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "mean_big_list = []\n",
    "std_big_list = []\n",
    "mean_small_list = []\n",
    "std_small_list = []\n",
    "mean_combo_list = []\n",
    "TA_up_thresh = []\n",
    "TA_below_thresh = []\n",
    "cum_ta_ang_mom_list = []\n",
    "cum_ha_ang_mom_list = []\n",
    "AngMom_TA_and_HA = []\n",
    "mean_combined_list = []\n",
    "std_combined_list = []\n",
    "Step_angle_list = []\n",
    "mean_step_list = []\n",
    "std_step_list = []\n",
    "combo_split_mean_list = []\n",
    "a = 0\n",
    "cum_ang_mom_dict = defaultdict(dict)\n",
    "\n",
    "for k in np.arange(len(search_key)):    \n",
    "\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all[search_key[k]]\n",
    "    values_list = list(dict_ridge_Xwidth.values())\n",
    "    key_list = list(dict_ridge_Xwidth.keys()) \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][-1]\n",
    "        COMX_traj_wrt_step = values_list[i][-1] \n",
    "        #print(TA_traj_wrt_step)\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            Tail_idx = 7\n",
    "            Hip_idx = 13\n",
    "            Tail_idx1 = 0\n",
    "            Tail_idx2 = 3\n",
    "            step_idx = 4 #step angle\n",
    "            if len(COMX_traj_wrt_step[j][Tail_idx]) and len(COMX_traj_wrt_step[j][Hip_idx]):# Plot Tail Angle trajectory\n",
    "                ang_mom_ta = (smooth((np.diff(COMX_traj_wrt_step[j][Tail_idx]))*0.5*(1/3)*49, 10))\n",
    "                ang_mom_ha = (smooth((np.diff(COMX_traj_wrt_step[j][Hip_idx]))*10*0.5*4, 10))\n",
    "                step_angle = smooth((COMX_traj_wrt_step[j][step_idx]), 10)\n",
    "                #plt.ylim(-50,420)\n",
    "                if len(COMX_traj_wrt_step[j][Tail_idx]) == 250 and len(COMX_traj_wrt_step[j][Hip_idx]) == 250:\n",
    "                    TA_up_thresh.append(ang_mom_ha)#Ang Mom HA\n",
    "                    cum_ha_ang_mom = np.trapz(abs(ang_mom_ha))\n",
    "                    cum_ha_ang_mom_list.append(cum_ha_ang_mom)\n",
    "                    TA_below_thresh.append(ang_mom_ta)#Ang Mom TA\n",
    "                    AngMom_TA_and_HA.append(ang_mom_ta+ang_mom_ha)#Ang Mom TA + HA \n",
    "                    cum_ta_ang_mom = np.trapz(abs(ang_mom_ta)) #event btw 0.3-0.5 s\n",
    "                    cum_ta_ang_mom_list.append(cum_ta_ang_mom)\n",
    "                    #Get mean of array chunks equally split\n",
    "                    combo_split_tail = np.array(splitsequenceequally(ang_mom_ta[92:152], 6))\n",
    "                    combo_split_hip = np.array(splitsequenceequally(ang_mom_ha[92:152], 6))\n",
    "                    combo_split_ratio = combo_split_hip+combo_split_tail #second\n",
    "                    combo_split_mean_list.append(combo_split_ratio.tolist())\n",
    "                    #plot\n",
    "                    plt.plot(ang_mom_ta ,color = 'b', lw=0.05, alpha = 0.1)\n",
    "                    plt.plot(ang_mom_ha ,color = 'r', lw=0.05, alpha = 0.1)\n",
    "                    #plt.plot(ang_mom_ha+ang_mom_ta, color = 'k', lw=0.05, alpha = 0.1)\n",
    "                    plt.plot(step_angle, color = 'g', lw=0.05, alpha = 0.1)\n",
    "                    if len(COMX_traj_wrt_step[j][step_idx]) == 250: #make sure step array is full array\n",
    "                        Step_angle_list.append(step_angle[0:258])#step angle                  \n",
    "\n",
    "\n",
    "            plt.ylim(-100,100)\n",
    "cum_ang_mom_dict['all'] = combo_split_mean_list#, cum_ta_ang_mom_list\n",
    "mean_big, std_big = return_Mean_STD_forPSTH(TA_up_thresh)\n",
    "mean_small, std_small = return_Mean_STD_forPSTH(TA_below_thresh)\n",
    "mean_combined, std_combined = return_Mean_STD_forPSTH(AngMom_TA_and_HA)\n",
    "mean_big_list.append(mean_big)\n",
    "std_big_list.append(std_big)\n",
    "mean_small_list.append(mean_small)\n",
    "std_small_list.append(std_small)\n",
    "mean_combined_list.append(mean_combined)\n",
    "std_combined_list.append(std_combined)\n",
    "mean_step, std_step = return_Mean_STD_forPSTH(Step_angle_list)\n",
    "mean_step_list.append(mean_step)\n",
    "std_step_list.append(std_step)\n",
    "\n",
    "# cum_ta_ang_mom_list.append(cum_ta_ang_mom)\n",
    "# cum_ha_ang_mom_list.append(cum_ha_ang_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, ls_param, label_strings, clr):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    #label_strings = ['4mm', '5mm', '8mm', '10mm']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            x = np.linspace(0, 250/300, 258)\n",
    "            ax.plot(x, mean_array[i], c=clr, label = label_strings[i], ls = ls_param)\n",
    "            ax.fill_between(x, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.3, facecolor=clr)\n",
    "            ax.legend(loc=\"lower left\", prop={'size': 12})\n",
    "            ax.set_xlabel('Time (s)', fontsize=18)\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)', fontsize=18)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=14) \n",
    "#            ax.axvline(122/300,0,360, color = 'red')\n",
    "            ax.axvline(92/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(102/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(112/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(122/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(132/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(142/300,0,360, color = 'gray', lw=0.2)\n",
    "            ax.axvline(152/300,0,360, color = 'gray', lw=0.2)\n",
    "\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot combined trace as well\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = ['lightcoral', 'grey', 'red', 'green']\n",
    "label_strings_bl = ['Hip']\n",
    "label_strings_sl = ['Tail']\n",
    "label_strings_co = ['Tail+Hip']\n",
    "label_strings_step = ['step']\n",
    "\n",
    "\n",
    "ls_param_bl = '-'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl, clrs[1]) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl, clrs[0])\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combined_list, std_combined_list, ax, ls_param_sl, label_strings_co, clrs[2]) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_step_list, std_step_list, ax, ls_param_sl, label_strings_step, clrs[3]) \n",
    "\n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "#plt.xlim(50/300, 200/300)\n",
    " \n",
    "plt.savefig('no_pert_AngMomPSTH.svg', format='svg', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitsequenceequally(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot combined trace as well\n",
    "_, ax = plt.subplots(figsize=(9, 8))\n",
    "clrs = ['lightcoral', 'grey', 'red', 'green']\n",
    "label_strings_bl = ['Hip']\n",
    "label_strings_sl = ['Tail']\n",
    "label_strings_co = ['Tail+Hip']\n",
    "label_strings_step = ['step']\n",
    "\n",
    "\n",
    "ls_param_bl = '-'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = '--'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl, clrs[1]) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl, clrs[0])\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combined_list, std_combined_list, ax, ls_param_combo, label_strings_co, clrs[2]) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_step_list, std_step_list, ax, ls_param_sl, label_strings_step, clrs[3]) \n",
    "\n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "plt.xlim(92/300, 152/300)\n",
    " \n",
    "plt.savefig('no_pert_AngMomPSTH.svg', format='svg', dpi=1200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
