{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import math\n",
    "from math import acos, degrees\n",
    "from scipy.signal import find_peaks\n",
    "import os.path\n",
    "import glob\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import entropy\n",
    "import pylab as pl\n",
    "from numpy.fft import fft\n",
    "from scipy import stats\n",
    "import numpy\n",
    "from scipy import signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_width = 250\n",
    "#centr_rang = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract angle using 3 points coordinate\n",
    "def angle3pt(a, b, c):\n",
    "#    \"\"\"Counterclockwise angle in degrees by turning from c to a around b\n",
    "#        Returns a float between 0.0 and 360.0\"\"\"\n",
    "    ang = math.degrees(\n",
    "    math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getridofAngleJumps(alpha):\n",
    "    alpha_rad = [x*(np.pi)/180 for x in alpha]\n",
    "    alpha_rad = np.array(alpha_rad)\n",
    "    alpha_rad[~np.isnan(alpha_rad)] = np.unwrap(alpha_rad[~np.isnan(alpha_rad)])\n",
    "    alpha_unwrap= np.degrees(alpha_rad)\n",
    "    return alpha_unwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to get rid of ugly jumps due to angle range [0-360], input alpha that is a list of angles\n",
    "#def getridofAngleJumps(x):\n",
    "#    n = [ 0, *np.diff(x) ]\n",
    "##    #get rid of negative jumps\n",
    "#    for i in range(len(n)):\n",
    "#        if n[i] < -300:\n",
    "#            while x[i] < 200: #or x[i] == 'NaN':\n",
    "#                x[i] = x[i]+360\n",
    "#                i += 1\n",
    "#                if x[i] == 'NaN':\n",
    "#                    i += 1\n",
    "#    #get rid also of positive jumps\n",
    "##        if n[i] > 300:\n",
    "##            while x[i] > 300:\n",
    "##                x[i] = x[i]-360\n",
    "##                i += 1        \n",
    "#    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_acausal(x,frequency = 0.300):\n",
    "    #b, a = signal.butter(8, 0.150)\n",
    "    sos = signal.butter(4, frequency, output='sos')\n",
    "    y = signal.sosfiltfilt(sos, x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x,window_len=20,window='hanning'):\n",
    "#    \"\"\"smooth the data using a window with requested size.\n",
    "#    \n",
    "#    This method is based on the convolution of a scaled window with the signal.\n",
    "#    The signal is prepared by introducing reflected copies of the signal \n",
    "#    (with the window size) in both ends so that transient parts are minimized\n",
    "#    in the begining and end part of the output signal.\n",
    "#    \n",
    "#    input:\n",
    "#        x: the input signal \n",
    "#        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "#        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "#            flat window will produce a moving average smoothing.\n",
    "#\n",
    "#    output:\n",
    "#        the smoothed signal\n",
    "#        \n",
    "#    example:\n",
    "#\n",
    "#    t=linspace(-2,2,0.1)\n",
    "#    y=smooth(x)\n",
    "#    \n",
    "#    \n",
    "#    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "#    scipy.signal.lfilter\n",
    " \n",
    "#    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "#    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError(\"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('numpy.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract RidgeX trajectory from excel file\n",
    "def RidgeX_excel_to_array_preprocessed(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    RidgeX = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    #take just numeric values\n",
    "    RidgeX=pd.to_numeric(RidgeX.iloc[:,0])\n",
    "\n",
    " \n",
    "    return smooth(RidgeX.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot tail angle trajectory\n",
    "def plot_TailAngle(file_path, chunk_width, i, c):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "#    df = pd.read_csv(file_path)\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000':'tail1_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.1':'tail1_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.2':'tail1_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.3':'tail2_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.4':'tail2_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.5':'tail2_lik',                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.6':'tail3_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.7':'tail3_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.8':'tail3_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.tail1_x=pd.to_numeric(df.tail1_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_y=pd.to_numeric(df.tail1_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_x=pd.to_numeric(df.tail2_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_y=pd.to_numeric(df.tail2_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_x=pd.to_numeric(df.tail3_x[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_y=pd.to_numeric(df.tail3_y[c-chunk_width:c+chunk_width])\n",
    "    df.tail1_lik=pd.to_numeric(df.tail1_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail2_lik=pd.to_numeric(df.tail2_lik[c-chunk_width:c+chunk_width])\n",
    "    df.tail3_lik=pd.to_numeric(df.tail3_lik[c-chunk_width:c+chunk_width])\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.05\n",
    "    df.tail1_x.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail1_y.where((df.tail1_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_x.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail2_y.where((df.tail2_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_x.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.tail3_y.where((df.tail3_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        #x1,y1=df.tail1_x[i],df.tail1_y[i]\n",
    "        vertical = np.array([df.tail1_x[i],df.tail1_y[i]+10])\n",
    "        tail1 = np.array([df.tail1_x[i],df.tail1_y[i]])\n",
    "        tail2 = np.array([df.tail2_x[i],df.tail2_y[i]])    \n",
    "        tail3 = np.array([df.tail3_x[i],df.tail3_y[i]])\n",
    "    \n",
    "\n",
    "    #Change below to decide 3 points to determine angle\n",
    "        angle = angle3pt(tail2, tail1, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_RPAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.9':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.10':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.11':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.21':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.22':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.23':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RA_x[i],df.RA_y[i]+10])\n",
    "        RA = np.array([df.RA_x[i],df.RA_y[i]])\n",
    "        RP = np.array([df.RP_x[i],df.RP_y[i]])\n",
    "\n",
    "        angle = angle3pt(RP, RA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_LPAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.9':'LP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.10':'LP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.11':'LP_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.12':'LA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.13':'LA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.14':'LA_lik',\n",
    "                       \n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.24':'RA_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.25':'RA_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.26':'RA_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.21':'RP_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.22':'RP_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.23':'RP_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.RA_x=pd.to_numeric(df.RA_x[2:])\n",
    "    df.LA_x=pd.to_numeric(df.LA_x[2:])\n",
    "\n",
    "    df.RA_y=pd.to_numeric(df.RA_y[2:])\n",
    "    df.LA_y=pd.to_numeric(df.LA_y[2:])\n",
    "\n",
    "    df.RP_x=pd.to_numeric(df.RP_x[2:])\n",
    "    df.RP_y=pd.to_numeric(df.RP_y[2:])\n",
    "    df.LP_x=pd.to_numeric(df.LP_x[2:])\n",
    "    df.LP_y=pd.to_numeric(df.LP_y[2:])\n",
    "    \n",
    "    df.RA_lik=pd.to_numeric(df.RA_lik[2:])\n",
    "    df.LA_lik=pd.to_numeric(df.LA_lik[2:])\n",
    "    df.RP_lik=pd.to_numeric(df.RP_lik[2:])\n",
    "    df.LP_lik=pd.to_numeric(df.LP_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.RA_x.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LA_x.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    df.RA_y.where((df.RA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LA_y.where((df.LA_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    df.RP_x.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RP_y.where((df.RP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_x.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LP_y.where((df.LP_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    RP_x =  df.RP_x\n",
    "    LP_x =  df.LP_x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.LA_x[i],df.LA_y[i]+10])\n",
    "        LA = np.array([df.LA_x[i],df.LA_y[i]])\n",
    "        LP = np.array([df.LP_x[i],df.LP_y[i]])\n",
    "\n",
    "        angle = angle3pt(LP, LA, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return [alpha, smooth(RP_x), smooth(LP_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_HipAngle(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[trial_no])\n",
    "#    df = pd.read_csv(file_path)\n",
    "\n",
    "    #Rename marker columns\n",
    "    df.rename(columns={'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.15':'LH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.16':'LH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.17':'LH_lik',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.18':'RH_x',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.19':'RH_y',\n",
    "                          'DLC_resnet50_Ridge_walkMay27shuffle1_1000000.20':'RH_lik'}, \n",
    "                 inplace=True)\n",
    "\n",
    "    #take just numeric values\n",
    "    df.LH_x=pd.to_numeric(df.LH_x[2:])\n",
    "    df.LH_y=pd.to_numeric(df.LH_y[2:])\n",
    "    df.RH_x=pd.to_numeric(df.RH_x[2:])\n",
    "    df.RH_y=pd.to_numeric(df.RH_y[2:])\n",
    "    df.RH_lik=pd.to_numeric(df.RH_lik[2:])\n",
    "    df.LH_lik=pd.to_numeric(df.LH_lik[2:])\n",
    "\n",
    "    \n",
    "    #substitute low likelihood points with NaN\n",
    "    #df.tail1_x[]=np.nan\n",
    "    lik_thresh = 0.1\n",
    "    df.LH_x.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.LH_y.where((df.LH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_x.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "    df.RH_y.where((df.RH_lik>lik_thresh),np.NaN,inplace=True)\n",
    "\n",
    "    \n",
    "    #extract RP x and LP x\n",
    "    LH_x =  df.LH_x\n",
    "    LH_y =  df.LH_y\n",
    "    RH_x =  df.RH_x    \n",
    "    RH_y =  df.RH_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compute and plot tail angle in panda dataframe as last column\n",
    "    angles=[]\n",
    "    for i in range(df.shape[0]):\n",
    "        vertical = np.array([df.RH_x[i],df.RH_y[i]+10])\n",
    "        RH = np.array([df.RH_x[i],df.RH_y[i]])\n",
    "        LH = np.array([df.LH_x[i],df.LH_y[i]])\n",
    "\n",
    "        angle = angle3pt(LH, RH, vertical)\n",
    "        #Append\n",
    "        angles.append(round(angle,2))\n",
    "    df['Angles']=angles\n",
    "    df.head()\n",
    "    \n",
    "    #Create a list comprehension by chunking x (centroid X trajectory) in 'chunk_width' frames and alpha (tail angle traj)\n",
    "    #x = CentroidXY.X\n",
    "    alpha = df.Angles\n",
    "    #Get alpha value at perturbation time to centre the trace to that value\n",
    "#    alpha_centred = alpha[tot_peaks]\n",
    "    #Apply function to get rid of angle jumps\n",
    "    alpha = getridofAngleJumps(alpha)\n",
    "    #Apply function to smooth\n",
    "    alpha = smooth(alpha)\n",
    "#    TailAngle_traj = alpha[tot_peaks-chunk_width:tot_peaks+chunk_width]-[alpha[tot_peaks]-alpha_centred]# for i in tot_peaks]\n",
    "#    RP_x = RP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[RP_x[tot_peaks]]\n",
    "#    LP_x = LP_x[tot_peaks-chunk_width:tot_peaks+chunk_width]-[LP_x[tot_peaks]]\n",
    "\n",
    "#!    return [TailAngle_traj, alpha]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract centroid X Y trajectory\n",
    "def extract_Centroid(file_path, chunk_width, trial_no):\n",
    "    #Read csv file tail markers\n",
    "    CentroidXY = pd.read_csv(file_path[trial_no])\n",
    "\n",
    "    CentroidXY.rename(columns={'NaN':'X',\n",
    "                              'NaN.1':'Y'}, \n",
    "                     inplace=True)\n",
    "    #take just numeric values\n",
    "    CentroidXY.Centroid_x=pd.to_numeric(CentroidXY.X)\n",
    "    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "    CentroidX =  np.array(CentroidXY.Centroid_x)\n",
    "    CentroidY =  np.array(CentroidXY.Centroid_y)\n",
    "    return CentroidX, CentroidY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_delay(a, b):\n",
    "    corr_a_b = np.correlate(a-np.mean(a), b-np.mean(b), mode = 'full')\n",
    "    delay = np.where(corr_a_b == numpy.amin(corr_a_b))# -(np.size(corr_a_b)+1)/2\n",
    "    return delay[0]-(np.size(corr_a_b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot Right Paw angle trajectory\n",
    "def plot_Centroid_edge_dist(file_path, chunk_width, i):\n",
    "    #Read csv file tail markers\n",
    "    df = pd.read_csv(file_path[i])\n",
    "\n",
    "##Open Centroid file from top camera\n",
    "#CentroidXY = pd.read_csv('C:/Users/Salvo/Desktop/Ridge/DLC_videos/Videos_to_analyzeDLC/Ridge_MiceS20-S24_16thApril/perturbation_8mm_1/8_S22/Centroid.csv')\n",
    "\n",
    "    #Select 1st column csv file\n",
    "    matrix2 = df[df.columns[0]]#.as_matrix()\n",
    "    Centroid1stcol = matrix2.tolist() #file 1st column\n",
    "\n",
    "\n",
    "#    CentroidXY.rename(columns={'NaN':'dist'}, \n",
    "#                     inplace=True)\n",
    "    #take just numeric values\n",
    "    Centroid1stcol = np.array(pd.to_numeric(Centroid1stcol))\n",
    "#    CentroidXY.Centroid_y=pd.to_numeric(CentroidXY.Y)\n",
    "\n",
    "    #extract Centroid x and y\n",
    "#    CentroidX =  CentroidXY.Centroid_x\n",
    "#    CentroidY =  CentroidXY.Centroid_y\n",
    "    \n",
    "#    Centroid_list = CentroidX[tot_peaks-chunk_width:tot_peaks+centr_rang-chunk_width]#-[CentroidX[tot_peaks]]\n",
    "    \n",
    "#    Centroid_list = CentroidX[tot_peaks-chunk_width-100:tot_peaks-100]-[CentroidX[tot_peaks-100]]\n",
    "    return smooth(Centroid1stcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#np.arange(len(file_to_open)-25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def firstNonNan(listfloats):\n",
    "    i = 0\n",
    "    for item in listfloats:\n",
    "        i += 1\n",
    "        if math.isnan(item) == False:\n",
    "            return i\n",
    "\n",
    "#firstNonNan(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HIST_MI_2_var(a, b):\n",
    "    fig = plt.figure(figsize=(10,14))\n",
    "    ax1 = plt.subplot(311)\n",
    "    ax2 = plt.subplot(312)\n",
    "    hist_centr = ax1.hist(a, density=True, bins=30, color = 'orange')  # `density=False` would make counts\n",
    "    hist_tail = ax2.hist(b, density=True, bins=30, color = 'blue')  # `density=False` would make counts\n",
    "#    ent_cent = entropy(hist_centr[0], base=2)\n",
    "#    ent_tail = entropy(hist_tail[0], base=2)\n",
    "    MI_cent_tail = metrics.mutual_info_score(hist_centr[0], hist_tail[0])\n",
    "    return MI_cent_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_delay_array(var1, var2):\n",
    "    var1 = var1[~np.isnan(var1)] #centroid\n",
    "    var2 = var2[~np.isnan(var2)] #TA\n",
    "    #take the mean out\n",
    "#    var1 = var1-np.mean(var1)\n",
    "#    var2 = var2-np.mean(var2)\n",
    "\n",
    "    corr_a_b = np.correlate(var1, var2, mode = 'full')\n",
    "    #norm_corr_a_b = np.correlate(var2/np.std(var2), var1/np.std(var1), mode = 'full')\n",
    "    cc_trace_midpoint = len(corr_a_b)\n",
    "    delay = np.argmax(abs(corr_a_b))-(cc_trace_midpoint/2)+1 #Get the delay of the absolute max peak\n",
    "    max_peak = max(corr_a_b)#, key=abs)\n",
    "#    max_peak = abs(max(corr_a_b, key=abs))\n",
    "    return delay, max_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(chunk_width, data):\n",
    "    # Number of sample points\n",
    "    N = chunk_width*2\n",
    "    # sample spacing\n",
    "    T = 1/300\n",
    "    x = np.linspace(0.0, N*T, N)\n",
    "    y = data\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0, 1/(2*T), N//2)\n",
    "#    plt.plot(xf, 2/N * np.abs(yf[0:N//2]))\n",
    "#    plt.grid()\n",
    "#    plt.show()\n",
    "    return xf, yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeaks_extractchunk(x_diff, x, y, z, w, w_x, t, other_step_x, ba, threshold_height, chunk_width_step):\n",
    "    peaks, _ = find_peaks(x_diff, height=threshold_height, distance = 50, prominence = 1)\n",
    "    out_step = []\n",
    "    out_TA = []\n",
    "    out_HA = []\n",
    "    out_cent = []\n",
    "    out_RstepAng = []\n",
    "    out_cent_X = []\n",
    "    out_ba = []\n",
    "    out_contra_step_x = []\n",
    "    for i in np.arange(len(peaks)):\n",
    "        chunk_trial_step = x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_contra_step = other_step_x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_TA = y[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_HA = z[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_cent = w[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_centX = w_x[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_RstepAng = t[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        chunk_trial_BA = ba[peaks[i]-chunk_width_step:peaks[i]+chunk_width_step]\n",
    "        \n",
    "\n",
    "        out_step.append(chunk_trial_step)\n",
    "        out_TA.append(chunk_trial_TA)\n",
    "        out_HA.append(chunk_trial_HA)\n",
    "        out_cent.append(chunk_trial_cent)\n",
    "        out_cent_X.append(chunk_trial_centX)\n",
    "        out_ba.append(chunk_trial_BA)\n",
    "        out_contra_step_x.append(chunk_trial_contra_step)\n",
    "        #transpose all traces of step angle greater than 360 back to 0\n",
    "        if np.nanmean(chunk_trial_RstepAng) > 250:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng-360)\n",
    "        elif np.nanmean(chunk_trial_RstepAng) < -150:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng+360)   \n",
    "        else:\n",
    "            out_RstepAng.append(chunk_trial_RstepAng)\n",
    "\n",
    "\n",
    "    \n",
    "    return out_step, out_TA, out_HA, out_cent, out_cent_X, out_RstepAng, out_contra_step_x, out_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.text as mpl_text\n",
    "\n",
    "class AnyObject(object):\n",
    "    def __init__(self, text, color):\n",
    "        self.my_text = text\n",
    "        self.my_color = color\n",
    "\n",
    "class AnyObjectHandler(object):\n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        print(orig_handle)\n",
    "        x0, y0 = handlebox.xdescent, handlebox.ydescent\n",
    "        width, height = handlebox.width, handlebox.height\n",
    "        patch = mpl_text.Text(x=0, y=0, text=orig_handle.my_text, color=orig_handle.my_color, verticalalignment=u'baseline', \n",
    "                                horizontalalignment=u'left', multialignment=None, \n",
    "                                fontproperties=None, rotation=45, linespacing=None, \n",
    "                                rotation_mode=None)\n",
    "        handlebox.add_artist(patch)\n",
    "        return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def delete_bad_traces_FromList(Traces_List, idx_to_eliminate):\n",
    "    for l in np.arange(len(idx_to_eliminate)):\n",
    "        for i in np.arange(len(Traces_List)):\n",
    "            for j in np.arange(len(Traces_List[i])):\n",
    "                if len(Traces_List[i][j]) == 200:\n",
    "                    if i == idx_to_eliminate[l][0] and j == idx_to_eliminate[l][1]:\n",
    "                        Traces_List[i][j] = [] \n",
    "    return Traces_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_trace(trace):\n",
    "    if np.nanmean(trace) <-50:\n",
    "        trace = trace + 360\n",
    "#    if np.nanmean(trace) >400:\n",
    "#        trace = trace - 360\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_trace_within_0_to_150(trace):\n",
    "    if np.nanmean(trace) <-50:\n",
    "        trace = trace + 360\n",
    "        if np.nanmean(trace) <-50:\n",
    "            trace = trace + 360\n",
    "#    elif np.nanmean(trace[0:60]) >150:\n",
    "#        trace = []\n",
    "    else:\n",
    "        trace = trace\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(arr):\n",
    "#     mask = np.isnan(arr)\n",
    "#     idx = np.where(~mask,np.arange(mask.size),0)\n",
    "#     np.maximum.accumulate(idx, out=idx)\n",
    "#     arr[mask] = arr[idx]\n",
    "    df = pd.DataFrame(data=arr.flatten())\n",
    "    df = df.fillna(value=None, method='backfill', axis=None, limit=70, downcast=None)\n",
    "    arr = df.values\n",
    "#    print(type(arr))\n",
    "    return arr.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Program Files\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Program Files\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: Mean of empty slice\n",
      "C:\\Program Files\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "### Organize all data into python dict\n",
    "from collections import defaultdict\n",
    "\n",
    "search_key_path = ['*4mm*', '*5mm*', '*8mm*', '*10mm*']\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "\n",
    "dict_ridge_all = defaultdict(dict)\n",
    "for j in np.arange(len(search_key)):\n",
    "    data_location = \"C://Users//SWAS92//Desktop//side_cam//\"\n",
    "    RidgeX_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Ridge_X//*.csv'))\n",
    "    TA_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'side_cam//*//*.csv'))\n",
    "    Centroid_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'Centroid_XY//*.csv'))\n",
    "    BodyAxis_ExcelList_to_open = glob.glob(os.path.join(os.path.sep, data_location, search_key_path[j], 'BodyAxis//*.csv'))\n",
    "\n",
    "#    print(RidgeX_ExcelList_to_open)\n",
    "#    dict_ridge = {}\n",
    "    for i in np.arange(len(RidgeX_ExcelList_to_open)): # len(peaks)\n",
    "        #fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "        #Extract arrays\n",
    "        RidgeX_traj = RidgeX_excel_to_array_preprocessed(RidgeX_ExcelList_to_open, chunk_width, i)\n",
    "        CentroidX_traj, CentroidY_traj = extract_Centroid(Centroid_ExcelList_to_open, chunk_width, i)\n",
    "        BodyAxis_traj = RidgeX_excel_to_array_preprocessed(BodyAxis_ExcelList_to_open, chunk_width, i)\n",
    "        #Extract traces of Centroid and Tail Angle around the time frame when the mouse is at the ridge center\n",
    "        a = firstNonNan(CentroidX_traj)\n",
    "        b = round((np.size(CentroidX_traj) - np.count_nonzero(np.isnan(CentroidX_traj)))/2)\n",
    "        c = a + b\n",
    "\n",
    "        #Take tail angle traj after extracting chunk of traj of interest around c\n",
    "        TailAngle_traj = plot_TailAngle(TA_ExcelList_to_open, chunk_width, i, c)\n",
    "\n",
    "        RidgeX_traj_chunk = fill_nan(RidgeX_traj[c-chunk_width:c+chunk_width])\n",
    "        TailAngle_traj_chunk = fill_nan(TailAngle_traj[c-chunk_width:c+chunk_width])\n",
    "        #TailAngle_traj_chunk_corrected = check_trace(TailAngle_traj_chunk)\n",
    "        CentroidX_traj_chunk = (CentroidX_traj[c-chunk_width:c+chunk_width])\n",
    "        CentroidY_traj_chunk = (CentroidY_traj[c-chunk_width:c+chunk_width])\n",
    "        BodyAxis_traj_chunk = fill_nan(BodyAxis_traj[c-chunk_width:c+chunk_width])\n",
    "        HipAngle_traj = plot_HipAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "        HipAngle_traj_chunk = fill_nan(HipAngle_traj[c-chunk_width:c+chunk_width])\n",
    "\n",
    "#         CentroidX_chunk  = CentroidX_traj[c-chunk_width:c+chunk_width]\n",
    "#         CentroidX_chunk_withoutNaN = CentroidX_traj[~np.isnan(CentroidX_traj)] #drop NaN\n",
    "     \n",
    "        #Compute R and L step \n",
    "        [RPAngle_traj, RP_x, LP_x]   = plot_RPAngle(TA_ExcelList_to_open, chunk_width, i)\n",
    "        RP_x = RP_x[c-chunk_width:c+chunk_width]\n",
    "        LP_x = LP_x[c-chunk_width:c+chunk_width]   \n",
    "        RPAngle_traj_chunk = fill_nan(RPAngle_traj[c-chunk_width:c+chunk_width])\n",
    "        \n",
    "        #divide trial into step-based chunks RIGHT\n",
    "        x_r = RP_x-np.nanmean(RP_x)\n",
    "        x_l = LP_x-np.nanmean(LP_x)\n",
    "        x_r_diff = np.diff(RP_x-np.nanmean(RP_x))\n",
    "        x_l_diff = np.diff(-(LP_x-np.nanmean(-LP_x)))\n",
    "        y_r = TailAngle_traj_chunk#-np.nanmean(TailAngle_traj)\n",
    "        y_l = TailAngle_traj_chunk#-np.nanmean(TailAngle_traj)\n",
    "        w = CentroidY_traj_chunk#-np.nanmean(Centroid_DIST_traj)#*50\n",
    "        z = HipAngle_traj_chunk#-np.nanmean(HipAngle_traj)\n",
    "        t = RPAngle_traj_chunk#-np.nanmean(RPAngle_traj)\n",
    "        ba = BodyAxis_traj_chunk\n",
    "        w_x = CentroidX_traj_chunk\n",
    "        step_chunk_R, TA_chunk_R, HA_chunk_R, cent_chunk_R, cent_chunk_XR, StepAngle_chunk_R, step_chunk_L_wrt_Rstep, \\\n",
    "        ba_wrt_Rstep = findpeaks_extractchunk(x_r_diff, x_r, y_r, z, w, w_x, t, x_l, ba, 0.9, chunk_width//2)\n",
    "        \n",
    "        #divide trial into step-based chunks LEFT\n",
    "        step_chunk_L, TA_chunk_L, HA_chunk_L, cent_chunk_L, cent_chunk_XL, StepAngle_chunk_L, step_chunk_R_wrt_Lstep, \\\n",
    "        ba_wrt_Lstep = findpeaks_extractchunk(x_l_diff, x_l, y_l, z, w, w_x, t, x_r, ba, 0.9, chunk_width//2)\n",
    "        \n",
    "        \n",
    "        #Decide here what variables to plot in the three figures\n",
    "        var1 = np.array(RidgeX_traj_chunk)\n",
    "        var2 = np.array(TailAngle_traj_chunk)\n",
    "        var3 = np.array(CentroidX_traj_chunk)\n",
    "        var4 = step_chunk_R\n",
    "        var5 = TA_chunk_R\n",
    "        var6 = step_chunk_L\n",
    "        var7 = TA_chunk_L\n",
    "        var8 = StepAngle_chunk_R\n",
    "        var9 = StepAngle_chunk_L\n",
    "        var10 = cent_chunk_R\n",
    "        var11 = cent_chunk_L\n",
    "        var12 = cent_chunk_XR\n",
    "        #var13 = cent_DistChunk_R\n",
    "        var13 = HA_chunk_R\n",
    "        var14 = StepAngle_chunk_R\n",
    "        var15 = step_chunk_L_wrt_Rstep\n",
    "        var16 = ba_wrt_Rstep\n",
    "        var17 = ba_wrt_Lstep\n",
    "        var18 = HA_chunk_L\n",
    "            \n",
    "        #Make dict\n",
    "        key_file_name = os.path.basename(RidgeX_ExcelList_to_open[i])\n",
    "        dict_ridge_all[search_key[j]][key_file_name] = [var1, var2, var3, var4, var5, var6, var7, \\\n",
    "                                                        var8, var9, var10, var11, var12, var13, var14, var15, \\\n",
    "                                                        var16, var17, var18]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_dict_value_ridge_pos(dict_ridge):\n",
    "    #Divide trials based on ridge position. Assign -1 for left tilt, +1 for right and 0 for no tilts. Append to 4th col\n",
    "    #Changed the threshold from 5000 to 10000 bcs M53 detected many no pert trials as pert\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "\n",
    "        ridge_array = dict_ridge[key_list[i]][0]\n",
    "        ridge_array_translated_nonNaN = ridge_array[~np.isnan(ridge_array)]\n",
    "        ridge_array_translated_nonNaN_mean_centered = ridge_array_translated_nonNaN-  \\\n",
    "        np.nanmean(smooth(ridge_array_translated_nonNaN[20:40]))\n",
    "        ridge_array_translated_int = np.trapz(smooth(ridge_array_translated_nonNaN_mean_centered, 50))\n",
    "        ridge_array_translated_nonNaN_mean_centered_diff_max = max(np.diff(ridge_array_translated_nonNaN_mean_centered))\n",
    "        if ridge_array_translated_int < -3000 and ridge_array_translated_nonNaN_mean_centered_diff_max<40:\n",
    "            dict_ridge[key_list[i]].append(-1)\n",
    "            #print(ridge_array_translated_nonNaN_mean_centered_diff_max)\n",
    "        elif ridge_array_translated_int > +3000 and ridge_array_translated_nonNaN_mean_centered_diff_max<40:\n",
    "            dict_ridge[key_list[i]].append(1)\n",
    "    #        print(ridge_array_translated_int)\n",
    "\n",
    "        else:\n",
    "            dict_ridge[key_list[i]].append(0)    \n",
    "    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_pert_trials_from_dict(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    for i in np.arange(len(key_list)):\n",
    "        Ridge_classvalue = values_list[i][-1]\n",
    "        if Ridge_classvalue == 1 or Ridge_classvalue == -1:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeNaNTATraces(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is mostly NaN\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][1]\n",
    "        no_of_nan_TAtraj = list(np.isnan(TA_traj))\n",
    "        count_NaN = no_of_nan_TAtraj.count(1)\n",
    "        if count_NaN>70:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)\n",
    "        elif len(TA_traj) == 0:\n",
    "            key_to_be_deleted = key_list[i]\n",
    "            dict_ridge.pop(key_to_be_deleted, None)    \n",
    "    return dict_ridge      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_traces_0_360_range(dict_ridge):\n",
    "    #Transpose from dict all trials where the TA traj is outsude [0, 360] and append to 13th column \n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys())\n",
    "    #dict_TA_transpose = {}\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        key_to_change = key_list[i]\n",
    "        TA_to_append = []\n",
    "        for j in np.arange(len(TA_traj)):\n",
    "            if np.nanmean(TA_traj[j])>400:\n",
    "                TA_traj_pushed_down = TA_traj[j]-360\n",
    "                TA_to_append.append(TA_traj_pushed_down)      \n",
    "            elif np.nanmean(TA_traj[j])<-100:\n",
    "                TA_traj_pushed_up = TA_traj[j]+360\n",
    "                TA_to_append.append(TA_traj_pushed_up)\n",
    "            else:\n",
    "                TA_to_append.append(TA_traj[j])\n",
    "        dict_ridge[key_to_change].append(TA_to_append)    \n",
    "\n",
    "    return dict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesNON_0_360(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj is outside 0 to 360 \n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        for j in np.arange(len(TA_traj)):\n",
    "            #print(len(TA_traj))\n",
    "            if np.nanmean(TA_traj[j])>350:\n",
    "                TA_traj[j] = []\n",
    "            elif np.nanmean(TA_traj[j]) < 10:\n",
    "                TA_traj[j] = []\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTATracesHighDerivative(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj = values_list[i][4]\n",
    "        for j in np.arange(len(TA_traj)): # step\n",
    "            TA_diff = np.diff(TA_traj[j])\n",
    "            if np.any(TA_diff>8) or np.any(TA_diff<-8):\n",
    "                TA_traj[j] = []\n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_TA_ipsi_contra_within0_360_range(TA_traj):\n",
    "    if np.nanmean(TA_traj)>400:\n",
    "        TA_traj = TA_traj-360\n",
    "    elif np.nanmean(TA_traj)<-40:\n",
    "        TA_traj = TA_traj+360\n",
    "    return TA_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR, TA_traj_listwrtL):\n",
    "    TA_wrtIpsiStep = []\n",
    "    TA_wrtContraStep = []\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) < 180:\n",
    "        TA_wrtIpsiStep = TA_traj_listwrtR\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) > 180:\n",
    "        TA_wrtIpsiStep = -TA_traj_listwrtL+360\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) > 180:\n",
    "        TA_wrtContraStep = -TA_traj_listwrtR+360\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) < 180:\n",
    "        TA_wrtContraStep = TA_traj_listwrtL\n",
    "    return TA_wrtIpsiStep, TA_wrtContraStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_HA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR, TA_traj_listwrtL, Hip_traj_list_wrt_R, Hip_traj_list_wrt_L):\n",
    "    Hip_wrtIpsiStep = []\n",
    "    Hip_wrtContraStep = []\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) < 180:\n",
    "        Hip_wrtIpsiStep = Hip_traj_list_wrt_R\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) > 180:\n",
    "        Hip_wrtIpsiStep = -Hip_traj_list_wrt_L+360+180\n",
    "    if np.nanmean(TA_traj_listwrtR[110:130]) > 180:\n",
    "        Hip_wrtContraStep = -Hip_traj_list_wrt_R+360+180\n",
    "    if np.nanmean(TA_traj_listwrtL[110:130]) < 180:\n",
    "        Hip_wrtContraStep = Hip_traj_list_wrt_L\n",
    "    return Hip_wrtIpsiStep, Hip_wrtContraStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeemptyarray(dict_ridge):\n",
    "    #Exclude from dict all trials where the TA traj derivative is high and return to COL 15\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_listwrtR = values_list[i][4]\n",
    "        TA_traj_listwrtL = values_list[i][6]\n",
    "        COM_traj_list = values_list[i][9]\n",
    "        COMX_traj_list = values_list[i][11]\n",
    "        #COMdist_traj_list = values_list[i][12]\n",
    "        Hip_traj_list_wrt_R = values_list[i][12]\n",
    "        Hip_traj_list_wrt_L = values_list[i][17]\n",
    "        StepAnlge_traj_list = values_list[i][13]\n",
    "        ContraStep_traj_list = values_list[i][14]\n",
    "        Step_x_traj_list = values_list[i][3]\n",
    "        values_to_append = []\n",
    "        for j, k in zip(np.arange(len(TA_traj_listwrtR)), np.arange(len(TA_traj_listwrtL))):\n",
    "            if len(TA_traj_listwrtR[j]) and len(COM_traj_list[j]):\n",
    "                #Transpose traces beyond 0-360 and exclude traces that are still beyon range\n",
    "                TA_traj_listwrtL_T = transpose_TA_ipsi_contra_within0_360_range(TA_traj_listwrtL[k])\n",
    "                TA_traj_listwrtR_T = transpose_TA_ipsi_contra_within0_360_range(TA_traj_listwrtR[j])\n",
    "                #divide TA traces based on contra step\n",
    "                TA_wrtIpsiStep, TA_wrtContraStep = decide_TA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                                       TA_traj_listwrtL_T)\n",
    "                HA_wrtIpsiStep, HA_wrtContraStep = decide_HA_traj_wrt_IpsiorContraStep(TA_traj_listwrtR_T, \\\n",
    "                                                                                       TA_traj_listwrtL_T, \\\n",
    "                                                                                       Hip_traj_list_wrt_R[j], \\\n",
    "                                                                                       Hip_traj_list_wrt_L[k])\n",
    "                #Assign to value in dict\n",
    "                values_to_append.append([TA_traj_listwrtR[j], COM_traj_list[j], COMX_traj_list[j], \\\n",
    "                                         #COMdist_traj_list[j], Hip_traj_list[j], StepAnlge_traj_list[j],\\\n",
    "                                         Hip_traj_list_wrt_R[j], StepAnlge_traj_list[j],\\\n",
    "                                         Step_x_traj_list[j], StepAnlge_traj_list[j], TA_wrtContraStep, \\\n",
    "                                         TA_wrtIpsiStep, TA_traj_listwrtL[k], ContraStep_traj_list[j], \\\n",
    "                                         Hip_traj_list_wrt_L[k], HA_wrtIpsiStep, HA_wrtContraStep])\n",
    "\n",
    "        dict_ridge[key_list[i]].append(values_to_append)\n",
    "    return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def excludeemptyarray_wrtLstep(dict_ridge):\n",
    "#     #Exclude from dict all trials where the TA traj derivative is high and return to COL 15\n",
    "#     values_list = list(dict_ridge.values())\n",
    "#     key_list = list(dict_ridge.keys()) #trial\n",
    "#     for i in np.arange(len(key_list)):\n",
    "#         TA_traj_listwrtL = values_list[i][6]\n",
    "#         COM_traj_list = values_list[i][9]\n",
    "#         COMX_traj_list = values_list[i][11]\n",
    "#         #COMdist_traj_list = values_list[i][12]\n",
    "#         Hip_traj_list = values_list[i][12]\n",
    "#         StepAnlge_traj_list = values_list[i][13]\n",
    "#         ContraStep_traj_list = values_list[i][14]\n",
    "#         Step_x_traj_list = values_list[i][3]\n",
    "#         values_to_append = []\n",
    "#         #print(len(TA_traj_listwrtL))\n",
    "#         for j in np.arange(len(TA_traj_listwrtL)):\n",
    "#             if len(TA_traj_listwrtL[j]):# and len(COM_traj_list[j]):\n",
    "#                 values_to_append.append([TA_traj_listwrtL[j]])#, COM_traj_list[j], COMX_traj_list[j], \\\n",
    "#                                          #COMdist_traj_list[j], Hip_traj_list[j], StepAnlge_traj_list[j],\\\n",
    "# #                                         Hip_traj_list[j], StepAnlge_traj_list[j],\\\n",
    "# #                                         Step_x_traj_list[j], ContraStep_traj_list[j]])\n",
    "\n",
    "#         dict_ridge[key_list[i]].append(values_to_append)\n",
    "#     return dict_ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstNonNan(listfloats):\n",
    "    i = 0\n",
    "    for item in listfloats:\n",
    "        i += 1\n",
    "        if math.isnan(item) == False:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to compute speed of COM\n",
    "def return_COM_speed(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        #print(values_list[14][-1])\n",
    "\n",
    "        COM_traj_list = values_list[i][-1]# last value in dict with COM empty array excluded\n",
    "        COM_to_append = []\n",
    "        for j in np.arange(len(COM_traj_list)):\n",
    "            COM_traj = COM_traj_list[j][1]\n",
    "            Centroid_DIST_traj_subtract1stelement = COM_traj-COM_traj[0]\n",
    "            Centr_vel = (Centroid_DIST_traj_subtract1stelement[-1])/np.size(COM_traj)\n",
    "            Centr_vel_pixelPersecond = Centr_vel *300 #300 Hz frames\n",
    "            COM_to_append.append(Centr_vel_pixelPersecond)\n",
    "        dict_ridge[key_list[i]].append(COM_to_append)  \n",
    "    return dict_ridge   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to compute speed of COM\n",
    "def return_TA_integral_Rstep(dict_ridge):\n",
    "    values_list = list(dict_ridge.values())\n",
    "    key_list = list(dict_ridge.keys()) #trial\n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_list = values_list[i][-2]# last value in dict with TA empty array excluded\n",
    "        #print(TA_traj_list)\n",
    "        TA_to_append = []\n",
    "        for j in np.arange(len(TA_traj_list)):\n",
    "            TA_traj = TA_traj_list[j][0]\n",
    "            TA_traj_diff = np.diff(TA_traj)\n",
    "            TA_traj_integral = np.trapz(TA_traj_diff[120:150])\n",
    "            TA_to_append.append(TA_traj_integral)\n",
    "        dict_ridge[key_list[i]].append(TA_to_append)  \n",
    "    return dict_ridge  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write script to pre-process and organize all pert trial into python dict\n",
    "\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "\n",
    "dict_preprocessed_all = defaultdict(dict)\n",
    "\n",
    "for i in np.arange(len(search_key)):\n",
    "    dict_ridge = dict_ridge_all[search_key[i]]\n",
    "    dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "    dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "    dict_ridge_excl_nan_traces = excludeNaNTATraces(dict_ridge_el_pert_trial)\n",
    "    dict_TA_transpose = transpose_traces_0_360_range(dict_ridge_excl_nan_traces)\n",
    "    dict_TA_transpose_btw_0_360_der_excluded_without_empty_array = excludeemptyarray(dict_TA_transpose)#dict_TA_transpose_btw_0_360)\n",
    "    dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Write script to pre-process and organize all pert trial into python dict wrt L step\n",
    "\n",
    "# search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "\n",
    "# dict_preprocessed_all_Lstep = defaultdict(dict)\n",
    "\n",
    "# for i in np.arange(len(search_key)):\n",
    "#     dict_ridge = dict_ridge_all[search_key[i]]\n",
    "#     dict_ridge_ridge_pos = assign_dict_value_ridge_pos(dict_ridge)\n",
    "#     dict_ridge_el_pert_trial = eliminate_pert_trials_from_dict(dict_ridge_ridge_pos)\n",
    "#     dict_ridge_excl_nan_traces = excludeNaNTATraces(dict_ridge_el_pert_trial)\n",
    "#     dict_TA_transposeL = transpose_traces_0_360_range(dict_ridge_excl_nan_traces)\n",
    "#     dict_TA_transpose_btw_0_360_der_excluded_without_empty_arrayL = excludeemptyarray_wrtLstep(dict_TA_transposeL)#dict_TA_transpose_btw_0_360)\n",
    "#     dict_preprocessed_all_Lstep[search_key[i]] = dict_TA_transpose_btw_0_360_der_excluded_without_empty_arrayL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bla = dict_ridge_all['4mm']\n",
    "\n",
    "values_list = list(bla.values())\n",
    "key_list = list(bla.keys())\n",
    "\n",
    "for i in np.arange(len(key_list)-1):\n",
    "    TA_traj = values_list[i][3]\n",
    "    step_L = values_list[i][5]\n",
    "    #fig, ax1 = plt.subplots(1, 1, figsize=(25,15))\n",
    "    for j, k in zip(np.arange(len(TA_traj)), np.arange(len(step_L))):\n",
    "         plt.plot(TA_traj[j])\n",
    "         plt.plot(step_L[k])\n",
    "         plt.xlim(110, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Write script to pre-process and organize all pert trial into python dict\n",
    "\n",
    "# search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "# dict_preprocessed_all = defaultdict(dict)\n",
    "\n",
    "# for i in np.arange(len(search_key)):\n",
    "#     dict_ridge = dict_ridge_all[search_key[i]]\n",
    "#     dict_ridge = assign_dict_value_ridge_pos(dict_ridge)\n",
    "#     dict_ridge = eliminate_pert_trials_from_dict(dict_ridge)\n",
    "#     dict_ridge = excludeNaNTATraces(dict_ridge)\n",
    "#     dict_TA_transpose = transpose_traces_0_360_range(dict_ridge)\n",
    "#     print(dict_TA_transpose.keys())\n",
    "#     dict_TA_transpose_btw_0_360 = excludeTATracesNON_0_360(dict_TA_transpose)    \n",
    "#     dict_preprocessed_all[search_key[i]] = dict_TA_transpose_btw_0_360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = dict_ridge_all['4mm']\n",
    "\n",
    "values_list = list(bla.values())\n",
    "key_list = list(bla.keys())\n",
    "\n",
    "for i in np.arange(len(key_list)-1):\n",
    "    TA_traj = values_list[i][11]\n",
    "    #print(TA_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PLOTS BEFORE PRE-PROCESS wrt R STEP\n",
    "#Plot trials for a specific width where all trials from the same animal are plot in the same plot (tot 15 plots) \n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "    dict_ridge_Xwidth = dict_ridge_all['4mm']\n",
    "    dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "    key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "#    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)    \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][4]\n",
    "        #print(TA_traj_wrt_step)\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            plt.plot(TA_traj_wrt_step[j] ,'y')\n",
    "            plt.title(\"{i}\".format(i = key_list[i]))\n",
    "            #plt.ylim(200, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTS BEFORE PRE-PROCESS wrt L STEP\n",
    "#Plot trials for a specific width where all trials from the same animal are plot in the same plot (tot 15 plots) \n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "    dict_ridge_Xwidth = dict_ridge_all['4mm']\n",
    "    dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "    key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "#    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)    \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][6]\n",
    "        #print(TA_traj_wrt_step)\n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            plt.plot(TA_traj_wrt_step[j] ,'y')\n",
    "            plt.title(\"{i}\".format(i = key_list[i]))\n",
    "            #plt.ylim(200, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excludeTA_outrange(TA):\n",
    "    if any(i < -30 or i > 250 for i in TA):\n",
    "        TA = []\n",
    "    return TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### PLOT POST PROCESS\n",
    "#Plot post-process TA wrt CONTRA step diff color for diff Mice\n",
    "Widths_key = ['4mm']#, '5mm', '8mm', '10mm']\n",
    "MouseID_key = ['M48']#, 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "foo_step_list = []\n",
    "TA_up_thresh = []\n",
    "TA_below_thresh = []\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "dict_traces_perMouseID_means = defaultdict(dict)\n",
    "dict_TA_125_contra = defaultdict(dict)\n",
    "\n",
    "for l in np.arange(len(Widths_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    list_TA_125_contra = []\n",
    "    for i in np.arange(len(MouseID_key)):\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all[Widths_key[l]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "        #Initialize\n",
    "        class_value_list_contra = []\n",
    "        class_value_list_ipsi = []\n",
    "        for k in np.arange(len(key_list)):\n",
    "            TA_traj_wrt_step = values_list[k][-1]\n",
    "            COMX_traj_wrt_step = values_list[k][-1]    \n",
    "            for j in np.arange(len(TA_traj_wrt_step)):\n",
    "                #Compute only TA traces that are within limit\n",
    "                TA_ipsi_inrange = excludeTA_outrange(COMX_traj_wrt_step[j][8])\n",
    "                TA_contra_inrange = excludeTA_outrange(COMX_traj_wrt_step[j][7])\n",
    "                if len(TA_contra_inrange):\n",
    "                    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "                    #plt.plot(TA_ipsi_inrange ,color = 'b', lw=0.4, alpha = 0.5)\n",
    "                    plt.plot(TA_contra_inrange ,color = 'r', lw=0.4, alpha = 0.5)\n",
    "                    TA_binning_value = TA_contra_inrange[100]\n",
    "                    TA_binning_value_list.append(TA_binning_value)\n",
    "                    plt.title(\"{i}\".format(i = key_list[k]))\n",
    "                    TA_125_contra = TA_contra_inrange[125]\n",
    "                    list_TA_125_contra.append(TA_125_contra)\n",
    "                    if len(TA_ipsi_inrange) == 250:\n",
    "                        class_value_list_ipsi.append(TA_ipsi_inrange)\n",
    "                    if len(TA_contra_inrange) == 250:\n",
    "                        class_value_list_contra.append(TA_contra_inrange)\n",
    "            dict_TA_125_contra[Widths_key[l]] = list_TA_125_contra\n",
    "        list_ipsi_mean = np.nanmean(class_value_list_ipsi, axis=0)\n",
    "        list_contra_mean = np.nanmean(class_value_list_contra, axis=0)\n",
    "        dict_traces_perMouseID[Widths_key[l]][MouseID_key[i]] = [list_ipsi_mean, \\\n",
    "                                                                 list_contra_mean]                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### PLOT POST PROCESS\n",
    "#Plot post-process TA wrt CONTRA step diff color for diff Mice\n",
    "Widths_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "foo_step_list = []\n",
    "TA_up_thresh = []\n",
    "TA_below_thresh = []\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "dict_traces_perMouseID_means = defaultdict(dict)\n",
    "dict_TA_125_contra = defaultdict(dict)\n",
    "\n",
    "for l in np.arange(len(Widths_key)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "    list_TA_125_contra_and_COMY_vel = []\n",
    "    for i in np.arange(len(MouseID_key)):\n",
    "        dict_ridge_Xwidth = dict_preprocessed_all[Widths_key[l]]\n",
    "        dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "        values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "        key_list = list(dict_ridge_XwidthXmouseID.keys()) \n",
    "        #Initialize\n",
    "        class_value_list_contra = []\n",
    "        class_value_list_ipsi = []\n",
    "        for k in np.arange(len(key_list)):\n",
    "            TA_traj_wrt_step = values_list[k][-1]\n",
    "            COMX_traj_wrt_step = values_list[k][-1]    \n",
    "            for j in np.arange(len(TA_traj_wrt_step)):\n",
    "                #Compute only TA traces that are within limit\n",
    "                TA_ipsi_inrange = excludeTA_outrange(COMX_traj_wrt_step[j][8])\n",
    "                TA_contra_inrange = excludeTA_outrange(COMX_traj_wrt_step[j][7])\n",
    "                if len(COMX_traj_wrt_step[j][1])==250 and len(TA_contra_inrange):\n",
    "                    #plt.plot(TA_ipsi_inrange ,color = clrs[i], lw=0.8, alpha = 0.5)\n",
    "                    plt.plot(COMX_traj_wrt_step[j][1]-COMX_traj_wrt_step[j][1][0] ,color = clrs[i], lw=0.8, alpha = 0.5)\n",
    "                    #TA_binning_value = COMX_traj_wrt_step[j][1][250]-COMX_traj_wrt_step[j][1][0]\n",
    "                    #TA_binning_value_list.append(TA_binning_value)\n",
    "                    plt.title(\"{i}\".format(i = key_list[k]))\n",
    "                    #print(COMX_traj_wrt_step[j][1])\n",
    "                    COMY_vel = COMX_traj_wrt_step[j][1][249]-COMX_traj_wrt_step[j][1][0]\n",
    "                    list_TA_125_contra_and_COMY_vel.append([COMY_vel, (TA_contra_inrange[130]-TA_contra_inrange[100])])\n",
    "                    #list_COMY_vel.append(COMY_vel)\n",
    "                    if len(TA_ipsi_inrange) == 250:\n",
    "                        class_value_list_ipsi.append(TA_ipsi_inrange)\n",
    "                    if len(TA_contra_inrange) == 250:\n",
    "                        class_value_list_contra.append(TA_contra_inrange)\n",
    "            dict_TA_125_contra[Widths_key[l]] = [list_TA_125_contra_and_COMY_vel]\n",
    "        list_ipsi_mean = np.nanmean(class_value_list_ipsi, axis=0)\n",
    "        list_contra_mean = np.nanmean(class_value_list_contra, axis=0)\n",
    "        dict_traces_perMouseID[Widths_key[l]][MouseID_key[i]] = [list_ipsi_mean, \\\n",
    "                                                                 list_contra_mean] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_TA_125_contra['4mm'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot to check that TA at beg of R step determines movement after R step peak velocity\n",
    "Widths_key = ['10mm']#, '5mm', '8mm', '10mm']\n",
    "\n",
    "for i in np.arange(len(Widths_key)):\n",
    "    dict_list = dict_TA_125_contra[Widths_key[i]][0]\n",
    "    #values_list = list(dict_list.values())\n",
    "    scatter_1 = [el [0] for el in dict_list]\n",
    "    scatter_2 = [el [1] for el in dict_list]\n",
    "    #print(scatter_1)\n",
    "    plt.scatter(scatter_1, scatter_2)\n",
    "    plt.ylim(-80,110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot means TA traces per mouse ID\n",
    "values_list = list(dict_traces_perMouseID.values())\n",
    "key_list = list(dict_traces_perMouseID.keys()) \n",
    "clrs = sns.color_palette(\"husl\", 4)\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "TA_all_traces_one_width_ipsi = []\n",
    "TA_all_traces_one_width_contra = []\n",
    "for l in np.arange(len(key_list)):\n",
    "    TA_per_mouse = values_list[l]\n",
    "    values_list_per_mouse = list(TA_per_mouse.values())\n",
    "    key_list_per_mouse = list(TA_per_mouse.keys()) \n",
    "    for color_i, i in zip(color_idx, np.arange(len(key_list_per_mouse))):\n",
    "#         #Plot here\n",
    "        plt.plot(values_list_per_mouse[i][0], c=clrs[l], lw=0.5, alpha = 0.7)\n",
    "        #plt.plot(values_list_per_mouse[i][1], c=clrs[l], lw=0.5, alpha = 0.7)\n",
    "        #plt.title('TA traces wrt Contra step')\n",
    "        TA_all_traces_one_width_ipsi.append(values_list_per_mouse[i][0])\n",
    "        #TA_all_traces_one_width_contra.append(values_list_per_mouse[i][1])\n",
    "\n",
    "    TA_mean_one_width_ipsi = np.nanmean(TA_all_traces_one_width_ipsi, axis=0)\n",
    "    #TA_mean_one_width_contra = np.nanmean(TA_all_traces_one_width_contra, axis=0)\n",
    "    plt.plot(TA_mean_one_width_ipsi, c=clrs[l], lw=3, alpha = 0.7, label = Widths_key[l])\n",
    "    #plt.plot(TA_mean_one_width_contra, '--',c=clrs[l], lw=3, alpha = 0.7, label = Widths_key[l])\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.axvline(125,0,360, color = 'red')\n",
    "plt.savefig('out3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Mean_STD_forPSTH(array_value_dict):\n",
    "    mean_array = np.nanmean(array_value_dict, axis = 0)\n",
    "    STD_array = stats.sem(array_value_dict, nan_policy='omit')\n",
    "    return mean_array, STD_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### PLOT POST PROCESS\n",
    "#Plot post-process TA wrt R step diff color for diff widths\n",
    "search_key = ['4mm', '5mm', '8mm', '10mm']\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "clrs = sns.color_palette(\"husl\", len(MouseID_key))\n",
    "mean_big_list = []\n",
    "std_big_list = []\n",
    "mean_small_list = []\n",
    "std_small_list = []\n",
    "mean_combo_list = []\n",
    "\n",
    "a = 0\n",
    "for k in np.arange(len(search_key)):\n",
    "    TA_up_thresh = []\n",
    "    TA_below_thresh = []\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all[search_key[k]]\n",
    "    values_list = list(dict_ridge_Xwidth.values())\n",
    "    key_list = list(dict_ridge_Xwidth.keys()) \n",
    "    for i in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[i][-1]\n",
    "        COMX_traj_wrt_step = values_list[i][-1] \n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            Tail_idx = 7\n",
    "            Hip_idx = 13\n",
    "            if len(COMX_traj_wrt_step[j][Tail_idx]):# Plot Tail Angle trajectory\n",
    "                a = a+1\n",
    "                #print(a)\n",
    "                plt.plot(COMX_traj_wrt_step[j][Tail_idx] ,color = 'b', lw=0.5, alpha = 0.1)\n",
    "                plt.ylim(-50,420)\n",
    "                if len(COMX_traj_wrt_step[j][Tail_idx]) == 250:\n",
    "                    TA_below_thresh.append((np.diff(COMX_traj_wrt_step[j][Tail_idx]))*0.5*(1/3)*49)#Ang Mom TA\n",
    "            if len(COMX_traj_wrt_step[j][Hip_idx]): #Plot Hip Angle trajectory\n",
    "                plt.plot(COMX_traj_wrt_step[j][Hip_idx] ,color = 'r', lw=0.5, alpha = 0.1)\n",
    "                if len(COMX_traj_wrt_step[j][Hip_idx]) == 250:\n",
    "                    TA_up_thresh.append((np.diff(COMX_traj_wrt_step[j][Hip_idx]))*20*0.5*4)#Ang Mom HA\n",
    "    mean_big, std_big = return_Mean_STD_forPSTH(TA_up_thresh)\n",
    "    mean_small, std_small = return_Mean_STD_forPSTH(TA_below_thresh)\n",
    "    mean_big_list.append(mean_big)\n",
    "    std_big_list.append(std_big)\n",
    "    mean_small_list.append(mean_small)\n",
    "    std_small_list.append(std_small)\n",
    "    mean_combo_list.append(mean_small+mean_big)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PSTH_Mean_STD_label_color_pre_assigned(mean_array, std_array, ax, ls_param, label_strings):\n",
    "    clrs = sns.color_palette(\"husl\", len(mean_array))\n",
    "    #label_strings = ['4mm', '5mm', '8mm', '10mm']#, 'Ipsi 4mm', 'Contra 4mm', 'Ipsi 4mm', 'Contra 4mm']\n",
    "#    _, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    with sns.axes_style(\"darkgrid\"):\n",
    "        for i in range(len(mean_array)):\n",
    "            epochs = list(range(len(mean_array[i])))\n",
    "            ax.plot(epochs, mean_array[i], c=clrs[i], label = label_strings[i], ls = ls_param)\n",
    "            ax.fill_between(epochs, mean_array[i]-std_array[i], mean_array[i]+std_array[i], \\\n",
    "                            alpha=0.3, facecolor=clrs[i])\n",
    "            ax.legend(loc=\"lower left\")\n",
    "            ax.set_xlabel('Frame number (FR = 300 Hz)')\n",
    "            ax.set_ylabel('Angular Momentum (g-cm2/s)')\n",
    "            ax.axvline(125,0,360, color = 'red')\n",
    "            #ax.axvline(140,0,360, color = 'red')\n",
    "\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPSI\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "label_strings_bl = ['4mm Hip', '5mm Hip', '8mm Hip', '10mm Hip']\n",
    "label_strings_sl = ['4mm Tail', '5mm Tail', '8mm Tail', '10mm Tail']\n",
    "ls_param_bl = '--'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl)  \n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "plt.xlim(50, 200)\n",
    "plt.savefig('out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contra\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "label_strings_bl = ['4mm Hip', '5mm Hip', '8mm Hip', '10mm Hip']\n",
    "label_strings_sl = ['4mm Tail', '5mm Tail', '8mm Tail', '10mm Tail']\n",
    "ls_param_bl = '--'\n",
    "ls_param_sl = '-'\n",
    "ls_param_combo = 'dotted'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl)  \n",
    "# plot_PSTH_Mean_STD_label_color_pre_assigned(mean_combo_list, \\\n",
    "#                                             std_small_list, ax, ls_param_combo, label_strings_sl)    \n",
    "\n",
    "plt.xlim(50, 200)\n",
    "plt.savefig('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrt R step\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "label_strings_bl = ['4mm Hip', '5mm Hip', '8mm Hip', '10mm Hip']\n",
    "label_strings_sl = ['4mm Tail', '5mm Tail', '8mm Tail', '10mm Tail']\n",
    "ls_param_bl = '--'\n",
    "ls_param_sl = '-'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl)    \n",
    "plt.xlim(70, 170)\n",
    "plt.savefig('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrt L step\n",
    "_, ax = plt.subplots(figsize=(12, 8))\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "label_strings_bl = ['4mm Hip', '5mm Hip', '8mm Hip', '10mm Hip']\n",
    "label_strings_sl = ['4mm Tail', '5mm Tail', '8mm Tail', '10mm Tail']\n",
    "ls_param_bl = '--'\n",
    "ls_param_sl = '-'\n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_big_list, std_big_list, ax, ls_param_bl, label_strings_bl) \n",
    "plot_PSTH_Mean_STD_label_color_pre_assigned(mean_small_list, std_small_list, ax, ls_param_sl, label_strings_sl)    \n",
    "plt.xlim(70, 170)\n",
    "plt.savefig('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_histogram_classifier(lag, max_height, thresh = 0):\n",
    "    classifier = []\n",
    "    if lag > thresh and max_height > 0:\n",
    "        classifier = 0\n",
    "    elif lag > thresh and max_height < 0:\n",
    "        classifier = 1\n",
    "    elif lag < thresh and max_height > 0:\n",
    "        classifier = 2\n",
    "    elif lag < thresh and max_height < 0:\n",
    "        classifier = 3\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_quadrant_classifier(TA, no_quad = 6):\n",
    "    lst = np.arange(361)\n",
    "    chunks_list = np.array_split(lst, no_quad)\n",
    "    classifier = []\n",
    "    for i in np.arange(len(chunks_list)):\n",
    "        first_value = chunks_list[i][0]\n",
    "        last_value = chunks_list[i][-1]\n",
    "        if first_value <= TA < last_value:\n",
    "            classifier = i\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitsequenceequally(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_quadrant_classifier_equal_number(TA, no_quad, list_of_TAMeans_equally_split):\n",
    "    classifier = []\n",
    "    #print(len(list_of_TAMeans_equally_split))\n",
    "    for i in np.arange(len(list_of_TAMeans_equally_split)):\n",
    "        first_value = list_of_TAMeans_equally_split[i][0]\n",
    "        last_value = list_of_TAMeans_equally_split[i][-1]\n",
    "        if first_value <= TA <= last_value:\n",
    "            #print(first_value, last_value, i)\n",
    "            classifier = i\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split traces into N equally populated arrays\n",
    "MouseID_key = ['M48', 'M49', 'M50', 'M51', 'M52', 'M53', 'M54', 'M55', 'M56', 'M57', 'M58', 'M59', 'M60', 'M61', 'M62']\n",
    "\n",
    "dict_ridge_4mm = dict_preprocessed_all['all']\n",
    "dict_traces_divided_on_TA_criteria = defaultdict(dict)\n",
    "no_quad_to_plot = 100\n",
    "TA_classifier_criteria_array = np.array(TA_binning_value_list)\n",
    "#print(TA_classifier_criteria_array)\n",
    "TA_classifier_criteria_array_woutNaN = TA_classifier_criteria_array[~numpy.isnan(TA_classifier_criteria_array)]\n",
    "TA_classifier_criteria_array_woutNaN.sort()\n",
    "list_of_TAtraces_eq_split = splitsequenceequally(TA_classifier_criteria_array_woutNaN,no_quad_to_plot)\n",
    "for i in np.arange(len(MouseID_key)):\n",
    "    dict_ridge_Xwidth = dict_preprocessed_all['4mm']\n",
    "    dict_ridge_XwidthXmouseID = dict(filter(lambda item: MouseID_key[i] in item[0], dict_ridge_Xwidth.items())) \n",
    "    values_list = list(dict_ridge_XwidthXmouseID.values())\n",
    "    key_list = list(dict_ridge_XwidthXmouseID.keys())\n",
    "    class_value_list = []\n",
    "    for k in np.arange(len(key_list)):\n",
    "        TA_traj_wrt_step = values_list[k][-1]    \n",
    "        for j in np.arange(len(TA_traj_wrt_step)):\n",
    "            if len(TA_traj_wrt_step[j][7]) == 250:\n",
    "                Trial_classvalue = values_list[j][7]\n",
    "                #print(TA_traj_wrt_step, j)\n",
    "                TA_traj = TA_traj_wrt_step[j][7] ######### CHANGE THIS LINE TO ADJUST CLASSIFIER\n",
    "                #print(list_of_TAtraces_eq_split)\n",
    "                TA_classifier_criteria = TA_traj[100]\n",
    "                quadrant_value = assign_quadrant_classifier_equal_number(TA_classifier_criteria, no_quad_to_plot, list_of_TAtraces_eq_split)\n",
    "                #print(TA_classifier_criteria, quadrant_value)\n",
    "                class_value_list.append([TA_traj, quadrant_value])\n",
    "\n",
    "    dict_traces_divided_on_TA_criteria[MouseID_key[i]] = class_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Assign TA list for each quadrant in dict\n",
    "def compute_mean_values_insideDict(dict_traces_divided_on_TA_criteria, no_quad_to_plot):\n",
    "    values_list = list(dict_traces_divided_on_TA_criteria.values())\n",
    "    key_list = list(dict_traces_divided_on_TA_criteria.keys()) \n",
    "    dict_mean_quadrants = defaultdict(dict)\n",
    "    print(len(key_list))\n",
    "    for k in range(no_quad_to_plot):\n",
    "        TA_traj_list = []\n",
    "        for i in np.arange(len(key_list)):\n",
    "            for j in np.arange(len(values_list[i])):\n",
    "                TA_traj = values_list[i][j][0]\n",
    "                quad_class = values_list[i][j][1]\n",
    "                if quad_class == k and len(TA_traj)== 250:\n",
    "                    TA_traj_list.append(TA_traj)\n",
    "        dict_mean_quadrants[k] = TA_traj_list\n",
    "    return dict_mean_quadrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot quadrants\n",
    "values_list = list(dict_mean_quadrants.values())\n",
    "key_list = list(dict_mean_quadrants.keys()) \n",
    "\n",
    "for i in np.arange(len(key_list)):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(15,6))\n",
    "    values_quad = values_list[i]\n",
    "    for j in np.arange(len(values_quad)):\n",
    "        ax1.plot(values_quad[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute mean of values inside binned dictionary\n",
    "dict_mean_quadrants = compute_mean_values_insideDict(dict_traces_divided_on_TA_criteria, no_quad_to_plot)\n",
    "\n",
    "#Plot means\n",
    "values_list = list(dict_mean_quadrants.values())\n",
    "key_list = list(dict_mean_quadrants.keys()) \n",
    "color_idx = np.linspace(0, 1, no_quad_to_plot)\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "\n",
    "for color_i, i in zip(color_idx, np.arange(no_quad_to_plot)):#len(key_list)):\n",
    "    mean_quadrant_traces = np.nanmean(dict_mean_quadrants[i], axis=0)\n",
    "    data = mean_quadrant_traces#-np.nanmean(mean_quadrant_traces)\n",
    "    #Plot here\n",
    "    plt.plot(data, color=plt.cm.coolwarm(color_i), lw=1, alpha = 0.7, label=\"%s quadrant\" % (i+1))\n",
    "    plt.ylim(50,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_list = list(dict_mean_quadrants.values())\n",
    "key_list = list(dict_mean_quadrants.keys()) \n",
    "color_idx = np.linspace(0, 1, no_quad_to_plot)\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15,10))\n",
    "\n",
    "for color_i, i in zip(color_idx, np.arange(no_quad_to_plot)):#len(key_list)):\n",
    "    mean_quadrant_traces = np.nanmean(dict_mean_quadrants[i], axis=0)\n",
    "    data = mean_quadrant_traces#-np.nanmean(mean_quadrant_traces)\n",
    "    #Plot here\n",
    "    plt.plot(data, color=plt.cm.coolwarm(color_i), lw=1, alpha = 0.7, label=\"%s quadrant\" % (i+1))\n",
    "    plt.ylim(50,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
